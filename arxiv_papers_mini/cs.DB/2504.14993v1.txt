Accepted for publication at IEEE International Conference on Data Engineering (ICDE 2025)
Dual Utilization of Perturbation for Stream Data
Publication under Local Differential Privacy
Rong Du, Qingqing Ye∗, Yaxin Xiao, Liantong Yu, Yue Fu, Haibo Hu
Department of Electrical and Electronic Engineering, The Hong Kong Polytechnic University
roong.du@connect.polyu.hk, qqing.ye@polyu.edu.hk, yaxin.xiao@connect.polyu.hk,
liantong2001.yu@connect.polyu.hk, yuesandy.fu@connect.polyu.hk, haibo.hu@polyu.edu.hk
Abstract —Stream data from real-time distributed systems
such as IoT, tele-health, and crowdsourcing has become an
important data source. However, the collection and analysis
of user-generated stream data raise privacy concerns due to
the potential exposure of sensitive information. To address
these concerns, local differential privacy (LDP) has emerged as
a promising standard. Nevertheless, applying LDP to stream
data presents significant challenges, as stream data often
involves a large or even infinite number of values. Allocating a
given privacy budget across these data points would introduce
overwhelming LDP noise to the original stream data.
Beyond existing approaches that merely use perturbed values
for estimating statistics, our design leverages them for both
perturbation and estimation. This dual utilization arises from
a key observation: each user knows their own ground truth
and perturbed values, enabling a precise computation of the
deviation error caused by perturbation. By incorporating this
deviation into the perturbation process of subsequent values,
the previous noise can be calibrated. Following this insight,
we introduce the Iterative Perturbation Parameterization (IPP)
method, which utilizes current perturbed results to calibrate
the subsequent perturbation process. To enhance the robust-
ness of calibration and reduce sensitivity, two algorithms,
namely Accumulated Perturbation Parameterization (APP) and
Clipped Accumulated Perturbation Parameterization (CAPP)
are further developed. We prove that these three algorithms sat-
isfyw-event differential privacy while significantly improving
utility. Experimental results demonstrate that our techniques
outperform state-of-the-art LDP stream publishing solutions in
terms of utility, while retaining the same privacy guarantee.
I. I NTRODUCTION
In the era of big data, collecting and analyzing real-
time data streams are essential in many distributed systems
such as IoT, tele-health, and crowdsourcing, which contin-
uously generate ample amount of data. Typical examples
include real-time traffic updates for navigation systems such
as Google Maps and Waze [12], and consumer sentiment
analysis on peer review platforms like Yelp [34]. While these
stream data offer substantial benefits for big data analysis
and training AI models, they simultaneously bring forth
privacy issues due to the potential exposure of sensitive
personal information [5], [13].
Local Differential Privacy (LDP) [3], [6], [16], a crypto-
graphic technique extensively deployed in various real-world
contexts [ ?], [4], [11], [29], provides formal privacy guar-
antees by bounding the information leakage of individual
users through a privacy parameter ϵ. However, its direct
∗Corresponding author: Qingqing Yeapplication to stream data faces fundamental limitations.
In particular, user-level LDP [1] considers the worst-case
scenario and partitions the privacy budget according to the
composition theorem [19], where privacy budget division
across timestamps leads to exponential utility degradation
as accumulated noise overwhelms the original data. To
address the challenge of limited privacy budget in stream
data collection, two mainstream approaches have emerged
in existing research, i.e., relaxing privacy definitions and
reducing the amount of transmitted data.
For privacy relaxation, event-level LDP [1], [31] assigns
independent privacy budgets ϵto individual data points,
which improves utility at the cost of weakened privacy
guarantees across multiple timestamps. w-event LDP [17]
provides a more rigorous privacy guarantee by constraining
the budget allocation within sliding windows of length w.
For reducing data transmission, methods proposed in [11],
[32] allow users to report only at turning points, allocat-
ing more privacy budget to each reported point. However,
reporting at turning points reveals temporal information,
as the transmission time itself indicates when the original
data changes. To decouple the relationship between turning
points and time, Mao et al. [21] proposed PrivShape, which
first employs symbolic aggregate approximation to convert
numerical sequences into short strings, and then uses tree
structures to identify frequent string patterns. However, due
to the loss of detailed information, this method does not
perform well in estimating means and distributions for range
queries. Therefore, enhancing the utility while preserving
user privacy remains a key challenge in LDP-enabled stream
data analysis.
Departing from privacy budget allocation strategies, we
propose a novel approach that leverages perturbation results
of steam data in a dual manner. Beyond their conventional
role in statistical analysis, these results can serve as valuable
components for calibrating perturbation parameters. This
dual-purpose approach stems from a key observation that
each user knows both their own ground truth and perturbed
values, which enables the deviation error to be computed
precisely and in turn incorporated into subsequent values
to calibrate the previous noise. Leveraging this auxiliary
information, users can employ their locally perturbed values
to adjust subsequent inputs for the perturbation mechanism
A, effectively mitigating errors from previous perturbations.arXiv:2504.14993v1  [cs.CR]  21 Apr 2025
We rigorously prove that this approach satisfies w-event
LDP, as the adjust inputs process naturally dilutes individual
value information.
To implement this idea, we first introduce the Iterative
Perturbation Parameterization (IPP) algorithm as a strawman
proposal, which incorporates the deviation from the previous
perturbation to the current stream value as input for A.
Since the current perturbation is a cumulative effect of
all previous data points rather than just the nearest one,
we present the Accumulated Perturbation Parameterization
(APP) algorithm to determine the deviations up to the
current stream value. Through this process, the sensitivity
increases as the range of the aggregated result expands.
To mitigate this, we propose the Clipped Accumulated
Perturbation Parameterization (CAPP), an optimized version
of the APP that can reduce sensitivity while retaining most
of the perturbation information. Additionally, we extend our
perturbation parameterization scheme to time-slot sampling,
which is particularly advantageous for mean statistics of
subsequences while ensuring the accuracy of the published
stream data.
Our contributions are summarized as follows:
•To the best of our knowledge, this is the first work
that parameterizes input value based on perturbation
for publishing stream data under LDP, which signif-
icantly enhances utility over existing state-of-the-art
techniques.
•We define a new problem of subsequence data collec-
tion under LDP, for statistical analysis on subsequences
influenced by LDP while retaining rigorous privacy
guarantee, i.e., w-event LDP.
•We propose a time-slot sampling approach for subse-
quence mean statistics estimation over user sampling,
which further improves the utility of subsequence mean
estimation.
The remainder of this paper is organized as follows. In
Section II, we introduce some preliminaries of LDP. In
Section III, we formally define the problem and present a
baseline approach to demonstrate our core ideas. In Section
IV, we propose two optimized algorithms, followed by a
sampling-based solution in Section V. In Section VI, we
provide extensive experimental evaluations. Then we review
related studies in Section VII, and conclude the paper in
Section VIII.
II. P RELIMINARIES
A. Local Differential Privacy
Local Differential Privacy (LDP) [6], [16] is a modern
privacy-preserving standard that enables users to anonymize
their data before publishing. It is defined as follows:
Definition 1. A randomized algorithm Asatisfies ϵ-local
differential privacy ( ϵ-LDP), if and only if for any two values
xandx′, and all possible outputs y⊆Range (A), the
following condition holds:
P[A(x)∈y]≤eϵ·P[A(x′)∈y].The intuition of LDP is the probabilistic nature that
Amaps any particular input to an output according to a
distribution, controlled by the privacy budget ϵ. Therefore,
anyone is unable to tell any individual’s true answer from the
observed output ywith high confidence. Particularly, LDP
lifts up the dependency on a trusted collector that is inherent
in centralized differential privacy (DP) [8], [9], [22].
The following composition theorems of LDP provide a
way to analyze the cumulative privacy loss when multiple
LDP mechanisms are applied, either sequentially or in
parallel.
Theorem 1. (Sequential Composition) For any kmecha-
nisms providing ϵi-local differential privacy for each, the
sequence of all these mechanisms provides ϵseq-local differ-
ential privacy, where
ϵseq=Xk
i=1ϵi.
Theorem 2. (Parallel Composition) Each of the kmecha-
nisms provides ϵi-local differential privacy and operates on
a disjoint subset of the entire dataset, then the union of these
mechanisms provides ϵpar-local differential privacy, where
ϵpar= max
i{ϵi}.
These theorems are useful in theoretical analysis, as they
allow the calculation of overall privacy loss in complex
LDP scenarios and help in designing privacy-preserving
algorithms by managing the privacy budget. The sequential
composition theorem is particularly important for iterative
algorithms or when a user’s data is used multiple times,
whereas the parallel composition theorem is applied when
the dataset can be partitioned and separate analyses are run
on each partition.
B.w-event Privacy
w-event privacy [17] is an LDP model tailed for data
streams, which quantifies and limits privacy exposure within
sliding windows containing wevents. Specifically, this pri-
vacy model is defined on w-neighboring streams as follows.
Definition 2. (w-neighboring Streams ) Two streams S=
{S1, ..., S t}andS′={S′
1, ..., S′
t}of length tarew-
neighboring streams if they have at most wconsecutive
different elements. Formally, for any i, j∈ {1, . . . , t}and
i≤j, ifSi̸=S′
iandSj̸=S′
j, then j−i+ 1≤w.
Then we have the following definition of w-event privacy.
Definition 3. (w-event Privacy ) LetMbe a mechanism that
takes as input a stream of arbitrary size tand produces O
as its output. Msatisfies w-event ϵ-DP (or simply, w-event
privacy) if for any two w-neighboring streams StandS′
t,
the following inequality holds
Pr[M(S)∈O]≤eϵ·Pr[M(S′)∈O].
A mechanism satisfying w-event privacy can provide ϵ-
LDP guarantee in any sliding window of size w. In other
words, for any mechanism with w-event privacy, ϵcan be
viewed as the total available privacy budget in any sliding
window of size w.
User 1
User 2
User 3
User n0.20.30.20.10.20.10.50.20.80.2
0.10.40.50.30.2
0.60.50.40.30.2Data
CollectorData
Stream
Publication① ②
③
… …Fig. 1: Illustration of the data streams collection framework
C. Square Wave Mechanism
Square Wave (SW) [20] is a typical LDP mechanism for
estimating numerical value distribution. Each user processes
a numerical value in [0,1], and generates a sanitized value
in[−b,1 +b], where b=ϵeϵ−eϵ+1
2eϵ(eϵ−ϵ−1). Given an input value
v, the randomized output can be expressed as following:
Pr[SW(v) =v′] =p, if |v−v′| ≤b,
q, otherwise,
where p=eϵ
2beϵ+1andq=1
2beϵ+1. Upon receiving the
perturbed data, the data collector aggregates the original
distribution by using the Maximum Likelihood Estimation
(MLE) [25], and reconstructs the distribution of original
values.
III. P ROBLEM DEFINITION AND BASELINE
In this section, we elaborate on our problem setting, and
then introduce a baseline algorithm.
A. Data Collection Framework
Our problem setting involves a data collector and a group
of distributed users, as shown in Figure 1. In Step ①, each
user owns a continuous data stream. Since the data collector
is untrusted, in Step ②the users utilize LDP mechanisms
(e.g., SW [20]) to perturb their data and report the sanitized
version. Upon receiving the perturbed data streams from
the users, the data collector aggregates the inputs, with
the goal of reconstructing an estimated data stream closely
approximating the original one in Step ③. Finally, the data
collector releases the aggregated values, e.g., mean or trends.
B. Problem Definition
The objective of the data collector is to estimate sub-
sequences of users’ data while ensuring w-event privacy
(shown in Section II-B). Analyzing subsequences of data
streams reveals localized meaningful patterns, which greatly
aids data streams modeling and forecasting. To clarify, our
discussion will primarily focus on a single data stream from
one individual user, unless specified otherwise. Though this
paper focuses on the single user scenario, the principles and
algorithms discussed can be readily extended to accommo-
date multiple users.
The data collector aims to estimate a user’s subsequence,
denoted as X(i,j), which represents a continuous segment of
the data stream spanning from the i-th time slot to the j-th
time slot. Formally, it is defined as:
X(i,j)={xi, xi+1, . . . , x j}.To protect their data, users will perturb the data using
an LDP mechanism. In this paper, we employ the SW
mechanism (shown in Section II-C), which is considered
as state-of-the-art method for collecting numerical data. We
suppose the subsequence perturbed by SW is:
X′
(i,j)={x′
i, x′
i+1, . . . , x′
j}.
The data collector will then reconstruct a subsequence
ˆX(i,j)by aggregating the perturbed data streams collected
over that period as
ˆX(i,j)={ˆxi,ˆxi+1, . . . , ˆxj}.
Directly releasing ˆX(i,j)is referred to as stream data
publication . Aside from directly releasing the stream data,
the data collector may also perform statistical analysis on
ˆX(i,j)and publish the corresponding statistical results, such
as calculating and publishing the mean or identifying trends.
Specifically, the mean estimation for ˆX(i,j)is denoted as:
ˆM(i,j)=Pj
t=iˆxt
j−i+ 1.
C. Iterative Perturbation Parameterization (IPP)
In this section, we present a baseline algorithm named
Iterative Perturbation Parameterization (IPP) for stream data
publication, which iteratively adjusts input values based on
perturbation results. The core idea of IPP is to integrate last
perturbation deviation into the current value’s perturbation
process to mitigate errors. Specifically, let xtdenote the
original value at the t-th time slot, and x′
tthe corresponding
perturbed value. Instead of directly perturbing the original
value xt, the user will calculate the deviation between xt−1
andx′
t−1and add it to xtas the input value in order to
partially correct the error caused by the perturbation in xt−1.
We give the details of the IPP algorithm as follows.
The procedure of IPP. LetxI
tdenote the input value at
time slot t. As shown in Figure 2, our method is explained
as follows. For the original value x1= 0.01of the first
time slot, since no data has been uploaded previously, the
deviation is zero, and we have input value xI
1=x1. After
perturbing by SW, we obtain x′
1= 0 . Since the user
knows the original value and the perturbed one, the user can
calculate the deviation d1=x1−x′
1= 0.01, which will be
corrected in the next time slot when perturbing x2. The spe-
cific approach is to add this deviation to the second original
value, and we obtain the input value xI
2=d1+x2= 0.16.
We then continue to perturb xI
2and get a new perturbed
value x′
2= 0.19. From this, we obtain a new deviation
d2=x2−x′
2=−0.04, which is then added to x3. IPP
repeats this process until all values are collected.
It is important to note that when the original values are
in the range of [0,1], adding the deviation may result in the
range of the input value exceeding this range. To address this
issue, we simply clip xI
tto[0,1]. Specifically, if xI
t<0, we
setxI
t= 0, and if xI
t>1, we set xI
t= 1.
This algorithm achieves better utility, as proven by Lemma
III.1. It is worth noting that the p,q, and bthat appear in
the subsequent proofs are parameters of SW mechanism, as
illustrated in Section II-C.
0.01 0.16 0.12 0.18 0.20
0 0.19 0.15 0.15 0.250.01 0.15 0.16 0.17 0.18 Original value 𝒙𝒙𝒕𝒕
Input value 𝒙𝒙 𝒕𝒕𝑰𝑰
Perturbed value 𝒙𝒙𝒕𝒕′（+0.01）
Deviation 𝒅𝒅𝒕𝒕=𝒙𝒙𝒕𝒕−𝒙𝒙𝒕𝒕′（+0.01）（-0.04）（-0.04）
（+0.01）（+0 .01）
（+0.02）（+0.02） （0）1 2 3 4 5 Time slot 𝒕𝒕
sw sw sw sw swFig. 2: The procedure of IPP
Lemma III.1. Given data stream values X =
{x1, x2, . . . , x n}, let MD(M) =PM(xi)
n−Pxi
n
denote the mean deviation for algorithm M. We have
MD(IPP )< MD (SW).
Proof. Letd1, . . . , d ndenote the deviations obtained from
the SW mechanism, where the mean deviation MD(SW)
is given by:
MD(SW)=SW(x1) +···+SW(xn)−Pxi
n. (1)
Letd′
1, . . . , d′
ndenote the deviations obtained from
the IPP algorithm, where the mean deviation for IPP,
MD(IPP ), can be calculated as:
MD(IPP ) =SW(xI
1)+···+SW(xI
n)−Pxi
n.(2)
Consider any two consecutive time slots tandt−1in
Equation 1. By expanding SW(xt−1), we have:
TSW(t−1, t) =xt−1−dt−1+SW(xt)−(xt−1+xt)
n.
Consider any two consecutive time slots tandt−1in
Equation 2. By expanding SW(xI
t−1), we have:
TIPP(t−1, t)=xt−1−d′
t−1+SW(xI
t)−(xt−1+xt)
n
=xt−1−d′
t−1+SW(xt+d′
t−1)−(xt−1+xt)
n.
By design, the SW mechanism generates outputs that
closely approximate its input x. Consequently, the term
xt−1−d′
t−1+SW(xt+d′
t−1)yields results that better
approximate the true value xt−1+xt, whereas the term
xt−1−dt−1+SW(xt)introduces an additional error compo-
nentdt−1, resulting in larger deviations from the true value.
Thus, we have
TIPP(t−1, t)< TSW(t−1, t). (3)
Substituting Equation 3 into Equations 1 and 2, we obtain
the following result:
MD(IPP )−MD(SW)=
1
2(nX
t=2TIPP(t−1, t)−nX
t=2TSW(t−1, t))<0,
which means IPP can always achieve lower mean deviation
compared to directly perturbing stream data with the SW
mechanism.IV. CAPP: C LIPPED ACCUMULATED PERTURBATION
PARAMETERIZATION
Despite the benefits achieved by IPP in mitigating errors
of the most recent perturbed value, it is limited to addressing
a single perturbed value. A natural idea is extend our
perturbation parameterization to encompass previous values,
thereby enabling error correction from earlier perturbations.
However, continuously accumulating deviations will lead to
an unbounded increase in the input value range. Therefore,
we need to constrain the range of input values reasonably.
Based on these insights, we develop an advanced and effec-
tive algorithm called Clipped Accumulated Perturbation Pa-
rameterization (CAPP). To facilitate understanding, we first
present Accumulated Perturbation Parameterization (APP)
as an introductory solution, which considers all deviations
caused by previously collected values and gives an effective
post-processing method.
A. Accumulated Perturbation Parameterization (APP)
To account for accumulated perturbation errors in stream
data collection, we maintain an accumulated deviation Dof
all perturbation-induced deviations from previously collected
values. The key idea of APP is to adjust each new stream
value by incorporating the deviation Das part of the input.
The procedure of APP is presented in Algorithm 1.
Algorithm 1 Accumulated Perturbation Parameterization
Input: Privacy budget ϵ, window size w, original stream
{xi, . . . , x j}
Output: Collected data stream {x′
i, . . . , x′
j}
1:ϵw=ϵ/w
2:Initialize accumulated deviation D= 0
3:foreach time slot tdo
4: xI
t=truncate (xt+D,[0,1])
5: x′
t=SW(xI
t)withϵw
6: Calculate deviation dt=xt−x′
t
7: D=D+dt
8:end for
9:return {x′
i, . . . , x′
j}
The algorithm begins by calculating the privacy budget for
each stream value, denoted by ϵw, to ensure the algorithm
satisfies w-event privacy (line 1). It then sets an initial
accumulated deviation Dto zero since no value has been
collected yet (line 2). We then compute xI
tby adding Dto
the current value xt, then clip xI
tto [0,1] (line 4). The next
step is the perturbation process, yielding the perturbed output
x′
t(line 5). The algorithm then obtains the new deviation dt
(line 6) and adds it to Dto update the accumulated deviation
for future stream values (line 7). Finally, the data collector
collects all the perturbed data (line 9).
Post-processing. After collecting the perturbed data, we
proceed a smoothing step. The reason for including a
smoothing step is that the perturbation process of the SW can
introduce random positive or negative deviations. Smoothing
allows positive and negative deviations to counteract, thereby
further reducing errors.
For smoothing, we employ the simplest method, the
Simple Moving Average (SMA) [2]. The smoothing value
SMA x′
tat time slot t, with a smoothing window size of
2k+ 1, is as follows:
SMA x′
t=1
2k+ 1t+kX
r=t−kx′
r.
When dealing with boundary windows where the number of
available values is less than 2k+ 1, we simply average the
available values. After smoothing, we can publish the stream
data as follows:
ˆX(i,j)={SMA x′
i, . . . , SMA x′
t, . . . , SMA x′
j}.
Smoothing has no impact on the mean of the results
but can significantly improve the characterization of the
data stream. The benefits of using SMA as post-processing
of APP can be demonstrated by the following theoretical
justifications:
Lemma IV .1. Given a data stream X =
{xi, . . . , x t, . . . , x j}and its APP-perturbed version
X′={x′
i, . . . , x′
t, . . . , x′
j}, define Y={yi, . . . , y t, . . . , y j}
as the smoothed stream obtained by applying simple moving
average with window size s(s > 1) toX′. Then for any
time point t, we have V ar(yt)< V ar (x′
t).
Proof. Letdt=xt−x′
tdenote the deviation of xtfrom
its perturbed counterpart x′
t. The smoothed data point yt,
computed with a window size of s= 2k+ 1, is given by:
yt=x′
t−k+...+x′
t+...+x′
t+k
2k+ 1
=xt−k−dt−1+...+xt−dt+...+xt+k−dt+k
2k+ 1.
The expected value of ytis formulated as:
E[yt] =Ext−k...+xt+...+xt+k
2k+ 1
−Edt−k...+dt+...+dt+k
2k+ 1
.
Given that the deviations are bidirectional (both positive and
negative) and exhibit compensatory behavior, where positive
and negative deviations tend to counterbalance each other.
Therefore, smoothing effectively mitigates the impact of
perturbation noise for characterization. Next, we consider
the variance of yi. Since the noise is i.i.d., we have:
V ar(yt) =V arx′
t−k+...+x′
t+...+x′
t+k
2k+ 1
.
Due to the linearity of variance, we can express this as:
V ar(yt) =1
(2k+ 1)2V ar(x′
t−k+···+x′
t+···+x′
t+k)
=1
(2k+ 1)2(V ar(x′
t−k)+. . .+V ar(x′
t)+. . .V ar (x′
t+k)).
Because we do not know the specific results of the perturbed
data, we consider the variance of all values to be the same
asV ar(x′
t), from which we have:
V ar(yt) =(2k+ 1)V ar(x′
t)
(2k+ 1)2=V ar(x′
t)
2k+ 1.Thus, the variance of the smoothed value is smaller than
that of the originally perturbed value.
Theoretical analysis. The APP algorithm is designed to
guarantee w-event privacy while achieving enhanced utility,
as proven in Theorem 3, Lemma IV .2 and Lemma IV .3.
Theorem 3. Given any two w-neighboring streams Xand
Yand an arbitrary output Sfrom the APP algorithm, if
each stream value is allocated a privacy budget ofϵ
w, then
the APP algorithm satisfies w-event privacy.
Proof. Let’s start with a straightforward scenario: a stream
consisting of only two values, denoted as X={x1, x2}
andY={y1, y2}, with a window size of w= 2. Let
S={s1, s2}represent a possible output. Our APP algorithm
begins to calculate the input values xI
2andyI
2only after
receiving s1. Applying Bayes’ theorem [15], we arrive at
the following equation:
P{APP (x1, x2) =s1, s2}
P{APP (y1, y2) =s1, s2}=P(s1, s2|x1, x2+x1−s1)
P(s1, s2|y1, y2+y1−s1).
(4)
We will demonstrate the calculation of the joint distribution
P(s1, s2|x1, x2+x1−s1). Using the chain rule of proba-
bility, we can break down this joint distribution:
P(s1, s2|x1, x2+x1−s1)
=P(s1|x1, x2+x1−s1)P(s2|s1, x1, x2+x1−s1).(5)
Firstly, P(s1|x1, x2+x1−s1)simplifies to P(s1|x1)
since s1is generated solely based on x1through the SW
mechanism. For P(s2|s1, x1, x2+x1−s1), it simplifies to
P(s2|x2+x1−s1), ass1andx1become redundant given
x2+x1−s1. Therefore, Equation 4 becomes:
P(s1, s2|x1, x2+x1−s1)
P(s1, s2|y1, y2+y1−s1)=P(s1|x1)P(s2|x2+x1−s1)
P(s1|y1)P(s2|y2+y1−s1).
(6)
Since the APP algorithm primarily utilizes the SW mech-
anism, and each value is allocated a privacy budget of ϵ/2in
this case, for any output uand any output o, the probability
bounds can be expressed as q≤P(APP(u) =o)≤p. From
this, we deduce:
P(s1|x1)
P(s1|y1)≤p
q=eϵ
2. (7)
At the second time stamp, the user knows both x1and
x2. Moreover, s1is known to both the user and the data
collector: the user knows it because the perturbation is
executed locally, while the data collector receives s1during
the first time step. Consequently, x2+x1−s1is a constant
for user. Similar to Equation 7, we obtain:
P(s2|x2+x1−s1)
P(s2|y2+y1−s1)≤p
q=eϵ
2. (8)
While the sensitivity of xiin SW is 1, for x2+x1−s1it
increases to 2. We apply clipping to restrict x2+x1−s1to
[0,1], which reduces noise scale but without privacy leakage.
Therefore, the clipping operation still maintains ϵ-differential
privacy. Substituting equations (7) and (8) into equation (6),
we obtain:
P(s1, s2|x1, x2+x1−s1)
P(s1, s2|y1, y2+y1−s1)≤eϵ
2eϵ
2=eϵ.
To demonstrate w-event privacy for the APP algorithm,
we need to show that any perturbed subsequence of length
wsatisfies ϵ-differential privacy. Consider subsequences
{x1, . . . , x w}from Xand{y1, . . . , y w}from Y. With a
corresponding outcome subsequence S={s1, . . . , s w}and
its reverse Sr, we derive:
P{APP (x1, x2,... , x w)=S}
P{APP (y1, y2,... , y w)=S}
=P{APP (xw, xw−1,... , x 1)=Sr}
P{APP (yw, yw−1,... , y 1)=Sr}
=P(sw|xI
w). . . P (s2|xI
2)P(s1|x1)
P(sw|yIw). . . P (s2|yI
2)P(s1|y1),(9)
where xI
t=xt+D. Since xtandDare known constants
for users, when we use xI
tas the input of SW, we have
P(st|xI
t)
P(st|yI
t)<p
q=eϵ/w. Therefore, we conclude that:
P{APP (x1, x2,... , x w)=S}
P{APP (y1, y2,... , y w)=S}≤(p
q)w≤(eϵ/w)w≤eϵ.
(10)
Lemma IV .2. Given a subsequence xi, . . . , x twith corre-
sponding deviations bi, . . . , b tand an accumulated deviation
represented by D, letME(D)denote the deviation between
the estimated mean and ground turth mean for the corre-
sponding accumulated deviation D. We present the following
inequality:
ME(di, . . . , d t)< ME (di+1, . . . , d t)<···< ME (dt).
Proof. We prove this result inductively by analyzing streams
of increasing length. Starting with a basic case of two
consecutive values ( xt−1andxt), we extend the analysis
to three values, and finally generalize to an arbitrary stream
length of t−i+ 1 values. We consider the case when the
xI
tis not perturbed and the estimated mean is then:
x′
t−1+xI
t
2=x′
t−1+xt+xt−1−x′
t−1
2=xt−1+xt
2,
which is the true mean of {xt−1, xt}. Then we introduce
xt−2, we consider the case when the xI
tis not perturbed
similarly. The estimated mean is then:
x′
t−2+x′
t−1+xI
t
3
=x′
t−2+x′
t−1+xt+xt−1−x′
t−1+xt−2−x′
t−2
3
=xt−2+xt−1+xt
3.
Similar to the case {xt−2, xt−1, xt}, we can generalize
this to tvalues: when the t-th input value is not perturbed,
the estimated mean is:
xi+x2+···+xt
t−i+ 1,
which is the same as the ground truth. Assume the pertur-
bation result for xI
tisR. The range of Ris[−b,1 +b]. As
ϵapproaches 0, bapproaches1
2. Therefore, the maximum
range of Ris
−1
2,1 +1
2
. The final estimated mean de-viation depends only on the perturbation Rof the previous
item. And we have:
ME(dr, . . . , d t) =R
t−r+ 1.
When t−r≤1, the influence of Ron the numerator is
less than that on the denominator, and we can conclude that
the bias error increases as rbecomes larger.
Lemma IV .3. Let{x1, x2, . . . , x n}be the true time se-
ries,{x′
1, x′
2, . . . , x′
n}be the directly perturbed time series
without APP , and {y1, y2, . . . , y n}be the time series using
APP and smoothing. Define the cosine similarities between
the true time series and the two perturbed time series as
cos(θDirect) andcos(θAPP) . Then, the following inequal-
ity holds:
E[cos(θAPP)] >E[cos(θDirect )]
Proof. We demonstrate that APP combined with smoothing
achieves higher cosine similarity with the original time series
than direct perturbation. We define the cosine similarities as:
cos(θDirect ) =⟨x, x′⟩
|x||x′|=Pn
i=1xix′ipPi= 1nx2
ipPn
i=1(x′i)2
cos(θAPP) =⟨x, y⟩
|x||y|=Pn
i=1xiyipPn
i=1x2
ipPn
i=1y2
i
where x′
i=xi+βiwith βibeing random noise, and yi
is the APP-perturbed and smoothed time series. For direct
perturbation, βiis independent noise with E[βi] = 0 and
Var(βi) =σβ2. This affects the cosine similarity in two
ways. The numerator contains a noise term:
⟨x, x′⟩=nX
i=1xi(xi+βi) =|x|2+nX
i=1xiβi
While E[Pn
i=1xiβi] = 0 , the variance of this term is:
Var nX
i=1xiβi!
=nX
i=1x2
iVar(βi) =σ2
β|x|2
The denominator is inflated by noise, with expected squared
norm:
E[|x′|2] =E"nX
i=1(xi+βi)2#
=nX
i=1(x2
i+ 2xiE[βi] +E[β2
i]) =|x|2+nσ2
β
In contrast, APP leverages prior knowledge to generate
adaptive noise ηiwith lower variance Var(ηi) =σ2
η< σ2
β
and adaptively generated to align better with the original
signal structure. The APP-perturbed and smoothed time
series is defined as:
yi=1
si+⌊s/2⌋X
j=i−⌊s/2⌋(xj+ηj)
where sis the smoothing window size. The smoothing oper-
ation further reduces noise variance. Assuming independent
noise, the variance of smoothed noise becomes:
Var
1
si+⌊s/2⌋X
j=i−⌊s/2⌋ηj
=1
s2i+⌊s/2⌋X
j=i−⌊s/2⌋Var(ηj) =σ2
η
s
This dual advantage affects the cosine similarity: the
numerator’s noise component has reduced variance
Var 
⟨x, y⟩ − |x|2
< Var 
⟨x, x′⟩ − |x|2
, and the
denominator experiences less inflation:
E[|y|2]≈ |x|2+nσ2
η
sComparing the simplified expressions for expected cosine
similarities:
E[cos(θDirect )]≈1r
1 +nσ2
β
|x|2
versus
E[cos(θAPP)]≈1q
1 +nσ2
η
s|x|2
Since σ2
η< σ2
βands >1, we definitively havenσ2
η
s|x|2<nσ2
β
|x|2.
Therefore E[cos(θAPP)]>E[cos(θDirect )].
B. Clipped Accumulated Perturbation Parameterization
(CAPP)
In the IPP and APP algorithms, input values are directly
clipped to [0,1] before applying SW perturbation, which
is a simplistic approach that does not consider the privacy
budget or the impact of accumulated deviation on utility.
In CAPP, we first clip the accumulated values to a range
[l, u], then normalize them to [0,1]for SW perturbation, and
finally denormalize back to [l, u]. This approach provides
more flexibility in handling accumulated deviations while
maintaining privacy guarantees. The main content of this
subsection introduces the CAPP algorithm and demonstrates
how to determine optimal [l, u]ranges to achieve better
utility.
Algorithm 2 Clipped Accumulated Perturbation Parameter-
ization
Input: Privacy budget ϵ, windows size w
Output: ˆX(i,j)={ˆxi, . . . , ˆxt, . . . , ˆxj}
1:Determine landu;
2:ϵw=ϵ/w;
3:Initialize accumulated deviation D= 0
4:foreach time slot tdo
5: Update input value: xI
t=xt+D
6: Clipping:
xI
t=(
l,ifxI
t< l,
u,ifxI
t> u.
7: Normalization: xI
t=xI
t−l
u−l
8: Perturbation: x′
t=SW(xI
t)
9: Denormalization: x′
t=x′
t(u−l) +l
10: Calculate deviation: dt=xt−x′
t
11: D=D+dt
12:end for
13:ˆX(i,j)=SMA (X′
(i,j));
14:return ˆX(i,j)={ˆxi, . . . , ˆxt, . . . , ˆxj}The procedure of CAPP. The Algorithm 2 initiates by
determining the lower bound land upper bound ufor input
values (line 1). The privacy budget per time slot ϵwis
calculated (line 2), and an initial accumulated deviation D
is set to zero (line 3). For each xtwithin the stream, the
algorithm first retrieves an input value based on D. It then
ensures xI
tremains within the [l, u]bounds by clipping: if
xI
tfalls below the lower bound l, it is raised to l, and if
it exceeds the upper bound u, it is reduced to u(line 6).
Next, the algorithm normalizes the clipped input value to
the range [0,1]. This normalization satisfies the input range
requirement of the SW algorithm (lines 7-8). Following
this, the algorithm employs the SW to perturb xI
t, and the
perturbed value x′
tis then denormalized to the original range
[l, u](line 9). It computes the deviation dt(line 10) and the
accumulated deviation D(line 11). Finally, the algorithm
executes a smoothing procedure on the perturbed values and
returns the estimated stream data (lines 13-14).
According to Theorem 4, CAPP satisfies ϵ-LDP while
applying a clipping operation to the input values. This clip-
ping operation reduces the noise scale without compromising
privacy guarantees.
Theorem 4. Given any two w-neighboring streams Xand
Yand an arbitrary output Sfrom the CAPP algorithm with
any clip range [l, u], if each stream value is allocated a
privacy budget ofϵ
w, then the CAPP algorithm satisfies w-
event privacy.
Proof. For Equation 8, although x2+x1−s1is clipped to
[l, u], the normalization transformation ( xnorm=x−l
u−l), which
ensures the input is always restricted to [0,1], preserves the
privacy guarantees. Since both clipping and normalization
are deterministic operations, they neither introduce addi-
tional randomness nor alter the privacy budget of the original
mechanism. Therefore, the privacy guarantee remains:
P(s2|x2+x1−s1)
P(s2|y2+y1−s1)≤eϵ/2.
The remaining proof follows the same steps as in Theorem
3.
The choice of landu.The Algorithm 2 involves choosing
landu, which affect the utility of our method through dif-
ferent types of errors. As more stream values are collected,
the range of xI
texpands. Clipping xI
tinto a fixed range
[l, u]presents a trade-off: while a wider range preserves
extreme values, it leads to higher sensitivity, requiring larger
noise introduction and thus increasing sensitivity error es;
conversely, a narrow range reduces data sensitivity and
requires less noise for the same privacy guarantee, but
excessive narrowing discards some information, introducing
significant discarding error ed.
The specific processes for calculating esandedare
given as follows. We define an error function T(es, ed)to
determine the clipping bound:
T(es, ed) =es−ed. (11)
The calculation of [l, u]is based on T(es, ed):
l= 0−T(es, ed),
u= 1 + T(es, ed).
Sensitivity error es.This error quantifies the deviation
introduced by clipping. The calculation is defined as:
es=ex−E(SW(x))−1,
where x−E(SW(x))measures the deviation be-
tween the original and expected perturbed values. Using
ex−E(SW(x))−1instead of simply x−E(SW(x))to
measure error has two advantages. First, it ensures esap-
proaches 0 for large ϵ, where sensitivity reduction becomes
unnecessary. Second, the exponential function mapping in
ex−E(SW(x))−1can amplify even small differences between
the original value and perturbed value. Given the unknown
distribution of original data, we consider the worst-case
scenario where x= 1.
Discarding error ed.To characterize the discarding er-
rored, we first establish the probability density function
Dx=x−SW(x)to analyze the deviation distribution.
Based on this, we define edusing the standard deviation of
Dx. Formally:
ed=p
V ar(Dx).
Smaller ϵleads to larger V ar(Dx), indicating more sig-
nificant deviations, while clipping within a narrow range
would result in excessive information loss. Next, we give
the calculation process of V ar(Dx). First, the probability
density function of G(Dx)is:
G(Dx) =

q, ifDx∈[−1−b+x,−b],
p ifDx∈(−b, b),
q ifDx∈[b, b+x].
The expectation and variance of this distribution can be
calculated, with the results as follows. The expected value
ofDxis given by:
E(Dx) =q((1 + 2 b)x−(b+1
2)).
The expectation of G(D2
x)is:
E(D2
x)=q−3b2+6bx2−6bx+3b+3x2−3x+1
3+2pb3
3.
Foredcomputation, we similarly consider the worst-case
scenario with x= 1due to the unknown ground-truth. Then,
the variance of Dxis:
V ar(Dx) =E(D2
x)−(E(Dx))2
=2b3p
3−b2q2+b2q−bq2+bq−q2
4+q
3.
C. Discussion on Generalizability
Crowd-level statistics. We extend our analysis from
individual-level to crowd-level statistics by leveraging the
collective information from independently and identically
distributed (i.i.d.) users. Specifically, we first estimate in-
dividual statistics over a subsequence for each user, then
analyze the distribution of these statistics across the popula-
tion. For example, we estimate the mean values M′
1, . . . , M′
n
for each user’s subsequence and characterize the distributionDthat these values follow. We aim to demonstrate that
more accurate estimations of {M′
1, . . . , M′
n}can lead to a
more precise characterization of D. Formally, our theoretical
framework establishes that accurate individual-level esti-
mations inherently result in accurate crowd-level statistical
inferences, as formalized in Theorem 5.
Theorem 5. Given any user’s true feature value Aand
estimated feature value ˆA, with the estimation error bounded
by|ˆA−A| ≤β(where βis a fixed constant), when the
sample size Nis sufficiently large, the maximum difference
between the empirical distribution function FN(x)based on
the estimated values ˆAiand the true distribution function
F(x)does not exceed ηwith probability at least 1−δ, i.e.,
P
sup
x|FN(x)−F(x)| ≤η
≥1−δ,
where η > β is the given error bound and δis the confidence
parameter.
Proof. We need to analyze the difference between the em-
pirical distribution function FN(x) =1
NPN
i=1I(ˆAi≤x)
constructed from the estimated values ˆAiand the true
distribution function F(x) =P(A≤x).
To facilitate the analysis, we introduce the empirical
distribution function based on the true values Ai, defined
asFtrue
N(x) =1
NPN
i=1I(Ai≤x), and apply the triangle
inequality to decompose the total error into two parts:
sup
x|FN(x)−F(x)| ≤sup
x|FN(x)−
Ftrue
N(x)|+ sup
x|Ftrue
N(x)−F(x)|.
We first analyze the estimation error supx|FN(x)−
Ftrue
N(x)|. Since |ˆAi−Ai| ≤β, for any value of x, we
have:
Ai≤x⇒ˆAi≤x+β
and
ˆAi≤x⇒Ai≤x+β
This implies that, for each point x:
Ftrue
N(x−β)≤FN(x)≤Ftrue
N(x+β)
Therefore,
FN(x)−Ftrue
N(x)≤Ftrue
N(x+β)−Ftrue
N(x)
Ftrue
N(x)−FN(x)≤Ftrue
N(x)−Ftrue
N(x−β)
Since the growth rate of an empirical distribution function
does not exceed 1, we have:
sup
x|FN(x)−Ftrue
N(x)| ≤β
Next, we examine the convergence error supx|Ftrue
N(x)−
F(x)|. According to the Dvoretzky–Kiefer–Wolfowitz
(DKW) inequality, for any ϵ >0:
P
sup
x|Ftrue
N(x)−F(x)|> ϵ
≤2e−2Nϵ2
Taking ϵ=η−βand setting 2e−2N(η−β)2≤δ, we obtain:
N≥ln(2/δ)
2(η−β)2
When the sample size satisfies the above condition, we
have:
P
sup
x|Ftrue
N(x)−F(x)| ≤η−β
≥1−δ
Combining these results, we obtain:
P
sup
x|FN(x)−F(x)| ≤β+ (η−β)
≥1−δ
P
sup
x|FN(x)−F(x)| ≤η
≥1−δ
This proves that when the sample size Nis sufficiently
large and satisfies N≥ln(2/δ)
2(η−β)2, the maximum difference
between the empirical distribution function FN(x)con-
structed from the estimated values and the true distribution
function F(x)does not exceed ηwith probability at least
1−δ.
Extension to other mechanisms. Our methods extend
beyond the SW mechanism to other numerical LDP mecha-
nisms, including Laplace [9], SR [7], and PM [30]. Applying
our approach to these mechanisms requires two key modi-
fications. First, we normalize the original data to [−1,1]to
accommodate the input requirements of these mechanisms.
Under this setting, the Laplace mechanism adds noise from
Lap(2/ϵ). Accordingly, the clipping process in IPP and APP
must also be adjusted to [−1,1]. Second, in CAPP, different
mechanisms require specific clip intervals [l, u]. Due to space
limitations, we omit the detailed discussion of these settings.
However, these mechanisms show inferior performance
compared to SW. This is primarily because SW provides
bounded perturbation results within (−1/2,3/2), regardless
of the privacy budget. In contrast, PM mechanism with
privacy budget ϵ= 0.01leads to perturbation in [−400,400].
Laplace mechanism generates perturbations well beyond
[−1,1]even with small noise. SR mechanism, limited to
outputs {−1,1}, loses substantial temporal information.
These limitations explain our focus on the SW mechanism
as the primary perturbation mechanism in this paper.
Extension to high-dimensional time series data . Our
scheme can be extended to high-dimensional time series
data, such as location information and trajectory data publi-
cation. We consider each dimensional time series indepen-
dently and apply our methods separately. To satisfy the com-
position theorem of differential privacy, we employ privacy
budget splitting and sampling techniques. Specifically, for
d-dimensional time series data collection, we propose two
approaches:
•Budget-Split (BS): At any given time slot, users upload
data for all dimensions, with each data point allocated a
privacy budget of ϵ/(dw). While this approach involves
uploading more data points, it results in higher noise
perturbation for each point.
•Sample-Split (SS): At any given time, users upload in-
formation for only one dimension, with each data point
allocated a privacy budget of ϵ/w. In this approach,
𝟏𝟏𝟐𝟐𝟑𝟑𝟒𝟒𝟓𝟓𝟔𝟔𝟕𝟕𝟖𝟖𝟗𝟗𝟏𝟏𝟏𝟏𝟏𝟏𝟏𝟏𝟏𝟏𝟐𝟐
𝜀𝜀
𝟑𝟑𝜀𝜀
𝟑𝟑𝜀𝜀
𝟑𝟑𝜀𝜀
𝟑𝟑𝜀𝜀
𝟑𝟑𝜀𝜀
𝟑𝟑𝜀𝜀
𝟑𝟑𝜀𝜀
𝟑𝟑𝜀𝜀
𝟑𝟑𝜀𝜀
𝟑𝟑𝜀𝜀
𝟑𝟑𝜀𝜀
𝟑𝟑
𝑎𝑎+b+𝑐𝑐
3𝑑𝑑+𝑒𝑒+𝑓𝑓
3𝑔𝑔+ℎ+𝑖𝑖
3𝑗𝑗+𝑘𝑘+𝑙𝑙
3
𝜀𝜀 𝜀𝜀 𝜀𝜀 𝜀𝜀Time slot
Sampling valueStrea mvalue
Privacy budget𝑎𝑎𝑏𝑏𝑐𝑐𝑑𝑑𝑒𝑒𝑓𝑓𝑔𝑔ℎ𝑖𝑖𝑗𝑗𝑘𝑘𝑙𝑙
Privacy budgetFig. 3: Illustration of the sampling
each window can only upload w/d data points, but the
noise perturbation for each point is lower.
V. P ERTURBATION PARAMETERIZATION ALGORITHMS
WITH SAMPLING
In this section, we combine sampling and perturbation pa-
rameterization (PP) algorithms to help enhance the accuracy
of mean statistics while ensuring stream data publication
remains satisfactory. Sampling approaches usually select a
few values for reporting to increase the per-value privacy
budget. However, if the number of values uploaded is too
small, it may degrade the utility of stream data publication.
To address this, we provide a perturbation parameterization
sampling method that determines the optimal number of
samples.
Sampling Design. Letnsrepresent the number of samples
for query X(i,j). To ensure w-event privacy in the sliding
window model: We divide the query interval [i, j]intons
segments, each containing ⌊j−i+1
ns⌋time slots1. For each
segment, we sample one value at a predetermined position.
The sampling positions remain consistent across different
windows to maintain privacy guarantees.
A naive approach of simply uploading the value at the
predetermined position to the data collector would result
in information loss. To maximize the uploaded information
while maintaining w-event local differential privacy, we
upload the mean value of each segment. The user’s original
sampled values are then:
S={s1, . . . , s r, . . . , s ns}.
where sris the mean value for the r-th segment.
Let us illustrate the sampling process with an example
in Figure 3, where w= 3. Without sampling, each value
must be uploaded individually with a privacy budget of ϵ/3.
In our sampling approach, we upload one aggregated value
for every three consecutive values by computing their mean.
This strategy allows us to increase the privacy budget for
each uploaded value from ϵ/3toϵ. Users then generate and
perturb these sampled mean values using our parameterized
perturbation algorithms before transmission to the data col-
lector.
1When (j−i+ 1) is not divisible by ns, the remaining time slots are
assigned to the last segment.
After going through our perturbation parameterization
algorithms, the perturbed values are:
S′={s′
1, . . . , s′
r, . . . , s′
ns}.
To restore the perturbed value for all time slots, we have:
X′={⌊j−i+1
ns⌋times
z}|{
s′
1, . . . , s′
1, . . . ,⌊j−i+1
ns⌋times
z}|{
s′
ns, . . . , s′
ns}.
Algorithm 3 Perturbation Parameterization Sampling
Input: Privacy budget ϵ, window size w, time interval [i, j]
Output: ˆX(i,j)={ˆxi, . . . , ˆxt, . . . , ˆxj}
1:Divide the [i, j]intonssegments
2:γ=min{⌊j−i+1
ns⌋, w},ϵw=ϵ/γ,X′=∅
3:foreach segment rdo
4: SetxI
ras the mean of current segment
5: x′
r=PP(xI
r) ▷Same as PP, APP, CAPP
6: X′=X′⊔ {x′
r}⌊j−i+1
ns⌋
7:end for
8:return X′(i,j)={x′i, . . . x′t, . . . , x′j}
The procedure of PP-S. By integrating sampling tech-
niques into Perturbation Parameterization methods (IPP,
APP, CAPP), we propose the Perturbation Parameterization
Sampling (PP-S) algorithm. The Algorithm 3 begins by
dividing the time interval [i, j]intonssegments (line 1).
It then determines the privacy budget per segment ϵwand
initializes an empty set X′(line 2). For each segment r, the
algorithm first calculates the mean value xI
rof the current
segment (line 4), and applies the Perturbation Parameteriza-
tion (PP) method to perturb xI
r(line 5). The perturbed value
is then replicated to match the segment size and added to
setX′(line 6). Finally, the algorithm returns the estimated
stream data X′(i,j)(line 8).
The choice of ns.As the number of samples nsdecreases,
each uploaded value gets a larger privacy budget, allowing
more accurate mean estimation. However, a smaller ns
compromises our ability to capture the stream characteristics
effectively. Our goal is to determine an optimal nsthat
balances accurate mean estimation with effective stream data
publication.
Specifically, we will then utilize the distribution of the
variance [23] of these nsvalues to help determine the final
size of ns. Given wwith a total privacy budget of ϵ, let
V ar(ns, ϵ)denote the variance for the sample variance after
sampling nstimes. The reason for using the variance of the
sample variance , rather than the sample variance itself, is
that it better reflects the variability and instability of the
sample variance statistic under repeated random sampling.
By multiplying the additional factor ns, we amplify the
impact of sampling size, and thus our objective function is:
argminnsnsV ar(ns, ϵ). (12)
Since ns∈ {1, . . . , j −i+ 1}is an integer, we can only
enumerate all possible values of nsand find the one that
minimizes the objective function.Next, we detail the calculation of V ar(ns, ϵ). According
to [23], SW(x)is independent and identically distributed,
then we have:
V ar(ns, ϵ) =1
ns
µ4−σ2(ns−3)
ns−1
, (13)
where σ2is the corresponding variance, µ4is the corre-
sponding fourth central moment, which are all parameters
related to ϵ. Due to unknown stream data, we examine
SW(x)atx= 1 (maximum variance case) and we obtain
the expectation µas follows:
µ=Z1+b
−bSW(x)dx
=q(2b−4bx+ 1)
2+ 2bpx= 2b(p−q)x+qb+q
2
= 2bp−bq+q
2.
Next, we derive the variance σ2, which is computed by the
following equation:
σ2=Z1+b
−b(x−µ)2SW(x)dx
=2b3p
3−b3q
3−4b2p2+ 4b2pq−b2q2+b2q
−2bpq+ 2bp+bq2−2bq
3−q2
4+q
3.
Finally, we determine the fourth central moment µ4, given
by the equation:
µ4=Z1+b
−b(x−µ)4SW(x)dx
=q
5+ 2bp−bq−qµ+ 4b3p+2b5p
5+ 2b2q
−2b3q+b4q+ 2qµ2−2qµ3+qµ4+ 12bpµ2−8bpµ3
−8b3pµ+ 2bpµ4−6bqµ2−6b2qµ+ 4bqµ3+ 4b3qµ
+ 4b3pµ2+ 6b2qµ2−8bpµ+ 4bqµ.
Guidelines for selecting the value of ns. We provide
heuristic guidelines for choosing nsbased on the distribu-
tional properties of the data. When nsincreases monotoni-
cally in Equation 12, V ar(ns, ϵ)must eventually exhibit a
decreasing pattern to achieve its minimum. According to the
definition of sample variance in Equation 13, for relatively
small values of ns, the objective function is primarily
determined by the fourth moment µ4, as the convergence
rate of the sample fourth moment substantially exceeds that
of1/n.
For heavy-tailed distributions (e.g., Cauchy distribution),
V ar(ns, ϵ)tends to grow without bound as nsincreases.
In such scenarios, selecting a relatively small nsis recom-
mended to prevent the potential explosion of V ar(ns, ϵ).
For light-tailed distributions (e.g., normal and uniform
distributions), extreme values have limited influence on the
fourth moment. Consequently, the fourth moment typically
exists and V ar(ns, ϵ)demonstrates rapid convergence with
increasing ns. Although the behavior of V ar(ns, ϵ)may be
complex for small ns, an optimal nsthat minimizes Equation
13 typically occurs near the point where V ar(ns, ϵ)begins
to decrease and stabilize. In these cases, selecting a moderate
value of nsrepresents a robust choice.
Theorem 6 proves that the Perturbation Parameterization
algorithm with sampling satisfies w-event LDP.
Theorem 6. LetXandYbe any two w-neighboring
subsequences, and let S′be an arbitrary output from the
Perturbation Parameterization algorithm with sampling (PP-
S), where PP-S represents IPP , APP , or CAPP . For a total
ofnwsampled values in each window, with each sampled
value allocated a privacy budget ofϵ
nw, the PP-S mechanism
achieves w-event local differential privacy.
Proof. Define F= (f1, . . . , f nw)as the sampling re-
sult from the stream X= (x1, x2, . . . , x w), and G=
(g1, . . . , g nw)as the sampling result from the stream Y=
(y1, y2, . . . , y w). Let S′= (s′
1, s′
2, . . . , s′
nw)denote the
perturbed output sequence and Srits reverse sequence.
Applying these definitions, Equation 9 can be rewritten as:
P{PP−S(f1, f2, ..., f nw) =S′}
P{PP−S(g1, g2, ..., g nw) =S′}
=P{PP−S(fnw, fnw−1, ..., f 1) =Sr}
P{PP−S(gnw, gnw−1, ..., g 1) =Sr}
=P(s′
nw|fI
nw). . . P (s′
2|fI
2)P(s′
1|f1)
P(s′nw|gInw). . . P (s′
2|gI
2)P(s′
1|g1)
≤(p
q)nw≤(eϵ/nw)nw≤eϵ.
VI. E XPERIMENTAL RESULTS
In this section, we conduct experiment to validate the
effectiveness of our proposed solutions.
A. Experimental Setup
The experiments are conducted on a PC equipped with
an AMD Ryzen 7 2700X eight-core processor, 64GB RAM,
and Windows 10, using MATLAB R2019b. The experiments
are conducted 100 times and the results were subsequently
averaged. All datasets and code are available online2.
1) Comparison algorithms: We categorize the compared
algorithms into two sets: those without sampling and those
with sampling. For the first set, we analyze several ap-
proaches, including a naive algorithm ( SW-direct ) that di-
rectly applies the SW perturbation method to each value, and
ToPL [31], a state-of-the-art method for mean estimation
from subsequences. We also compare BA-SW [17], [24],
which integrates budget absorption with the SW mechanism
to preserve the privacy budget by skipping the transmission
of minimally changed data points. Our proposed algorithms
in this set include IPP, APP, and CAPP. For the second
set, involving sampling, we compare a naive approach
(Sampling ) that samples stream values before applying the
SW mechanism, alongside our proposed methods APP-S and
CAPP-S.
2https://github.com/RONGDUGithub/CAPPAs for the smoothing step, it is necessary to determine
a smoothing window size. A larger window size offers
advantages in estimating the mean; however, it may result
in unfavorable outcomes for stream data publication. In our
experimental setting, we choose the smoothing window size
of 3.
2) Utility metrics: We classify our performance evalua-
tions into three categories: (a) mean estimation with Mean
Squared Error (MSE) assessment [18], (b) direct stream data
release evaluated by cosine distance [27], and (c) distribution
analysis of subsequence means using Wasserstein Distance
[26].
MSE. The Mean Squared Error, denoted as MSE, is
a commonly used metric to measure the average squared
difference between predicted values ˆyiand true values yiin
regression tasks. Given a set of npairs of predicted and true
values, the MSE is calculated as:
MSE =1
nnX
i=1(ˆyi−yi)2.
Cosine distance. The cosine distance [27], denoted as
dcos, measures the dissimilarity between two vectors in a
vector space. Given two vectors uandv, the cosine distance
is calculated as:
dcos(u,v) = 1−u·v
|u||v|.
where dcos·represents the dot product of the vectors, and
|·|denotes the Euclidean norm. If the cosine distance is high
(e.g., close to 1), indicating that the vectors are dissimilar.
Wasserstein Distance. Also known as Earth Mover’s Dis-
tance (EMD), it measures the minimum cost of transforming
one probability distribution into another. The Wasserstein
distance is computed as the sum of absolute differences
between two empirical CDFs FandG, as shown below:
W(F, G) =nX
i=1|Fi−Gi|.
A smaller Wasserstein distance indicates higher similarity
between the distributions.
3) Datasets: The experiments are conducted on four real-
world datasets. The Volume andC6H6 datasets each consist
of a single data stream from a single user, while the Taxi and
Power datasets contain multiple data streams from multiple
users. For the latter two datasets, we perform both user-level
and crowd-level statistical analysis.
Volume3.The dataset comprises hourly measurements of
westbound traffic volume from the Minnesota Department
of Transportation (MNDoT) Automatic Traffic Recorder
(ATR) station 301, strategically situated midway between
Minneapolis and St. Paul along Interstate 94. The data
stream contains a total of 48204 valid entries.
C6H64.The dataset encompasses 9,358 instances of
hourly averaged data collected by a suite of five metal oxide
chemical sensors integrated into an Air Quality Chemical
Multisensor Device, spanning from March 2004 to February
3https://archive.ics.uci.edu/dataset/492/metro+interstate+traffic+volume
4https://archive.ics.uci.edu/dataset/360/air+quality
0.511.522.531.2e-011.3e-011.4e-011.5e-011.6e-01MSESW-direct BA-SW IPP APP CAPP
0.511.522.53
 1.2e-011.2e-011.2e-01MSE(a)C6H6 ,w= 10 .
0.511.522.53
 2.5e-023.0e-023.5e-024.0e-02MSE (b)Volume ,w= 10 .
0.511.522.53
 2.0e-022.5e-023.0e-02MSE (c)Taxi,w= 10 .
0.511.522.53
 3.0e-024.0e-025.0e-026.0e-027.0e-02MSE (d)Power ,w= 10 .
0.511.522.53
 1.2e-011.2e-011.3e-011.4e-01MSE
(e)C6H6 ,w= 30 .
0.511.522.53
 1.8e-022.0e-022.2e-022.4e-022.6e-022.8e-02MSE (f)Volume ,w= 30 .
0.511.522.53
 8.0e-031.0e-021.2e-021.4e-021.6e-021.8e-02MSE (g)Taxi,w= 30 .
0.511.522.53
 1.0e-021.5e-022.0e-022.5e-02MSE (h)Power ,w= 30 .
0.511.522.53
 1.2e-011.2e-011.2e-011.2e-011.3e-011.3e-01MSE
(i)C6H6 ,w= 50 .
0.511.522.53
 1.2e-021.4e-021.6e-021.8e-02MSE (j)Volume ,w= 50 .
0.511.522.53
 6.0e-037.0e-038.0e-03MSE (k)Taxi,w= 50 .
0.511.522.53
 5.0e-031.0e-021.5e-02MSE (l)Power ,w= 50 .
Fig. 4: MSE comparison w.r.t. ϵfor perturbation parameterization based algorithms vs SW-direct
2005. We focus on the subset of data related to the fluctua-
tions in benzene concentration levels.
Taxi5.The dataset captures the real-time trajectories
of 10,357 taxis in Beijing, recorded from February 2 to
February 8, 2008. We focused on extracting the latitude
information for each taxi at 1307 specific timestamps from
1500 drivers.
Power6.This dataset is sourced from the UCR Time
Series Data Mining Archive. It contains the power usage data
of 25,562 electrical devices, with each time series consisting
of 96 stream values.
B. Overall Results for Perturbation Parameterization Algo-
rithms
1) The results for mean estimation:
Comparison of SW-based algorithms and ToPL. In
Table I, our comparative analysis primarily focuses on two
categories of algorithms. The first category encompasses
those based on the SW mechanism, which includes the SW-
direct, IPP, and APP algorithms. The second category is the
ToPL algorithm [31], which first uses the SW algorithm to
remove outlier data and obtain a reasonable data range, then
perturbs the data using the HM mechanism [30].
In Table I, we find that the MSE of ToPL is more than 100
times larger than others for mean estimation. This is because
the perturbation threshold mechanism of SW is much smaller
than that of HM. For example, when the privacy budget
5https://www.microsoft.com/en-us/research/publication/t-drive-
trajectory-data-sample/
6https://www.cs.ucr.edu/%20eamonn/time%20series%20data/TABLE I: Results for ToPl with SW-based algorithms
MSE w SW-direct IPP APP ToPL
C6H6
ϵ= 120 0.131 0.131 0.129 25.214
40 0.125 0.126 0.125 51.613
60 0.124 0.124 0.123 80.070
Taxi
ϵ= 120 1.28E-04 1.25E-04 1.19E-04 0.043
40 4.9E-05 4.8E-05 4.6E-05 0.132
60 3.7E-05 3.6E-05 3.5E-05 0.221
per window is 1, and there are 20 time slots, the privacy
budget allocated to each time slot is 0.05. The perturbation
threshold for SW is mapped from [0,1] to [-0.4836, 1.4836].
In contrast, the HM perturbation threshold is mapped from
[-1,1] to [-80,80]. Thus, it is evident that ToPL incurs a
larger error with a smaller privacy budget. Furthermore,
the order of magnitude of this error increases exponentially
as epsilon decreases. Due to the significant discrepancy of
ToPL’s results compared to PP methods, we will not include
them in our subsequent experimental result figures.
Comparison on PP algorithms and SW-direct & BA-
SW. In Figure 4, we compare MSE for mean estimation
among the SW-direct, BA-SW and our PP algorithms (IPP,
APP, and CAPP). We compute the average over 50 randomly
sampled time subsequences with length w.
We observe that in most subfigures, the MSE of BA-SW
is the largest compared to our perturbation parameterization
algorithms, with SW-direct performing as the second worst.
The utility of APP is better than that of IPP, as APP
leverages more perturbation information from the stream
values, resulting in smaller errors in mean estimation, as
demonstrated by Lemma IV .2. Notably, CAPP achieves the
0.511.522.531.2e-011.3e-011.4e-011.5e-011.6e-01MSESW-direct BA-SW IPP APP CAPP
0.511.522.53
 3.0e-013.5e-014.0e-01Cosine distance(a)C6H6 ,w= 10 .
0.511.522.53
 2.5e-013.0e-013.5e-014.0e-01Cosine distance (b)Volume ,w= 10 .
0.511.522.53
 1.5e-012.0e-012.5e-013.0e-01Cosine distance (c)Taxi,w= 10 .
0.511.522.53
 1.5e-012.0e-012.5e-013.0e-01Cosine distance (d)Power ,w= 10 .
0.511.522.53
 3.0e-013.5e-014.0e-01Cosine distance
(e)C6H6 ,w= 30 .
0.511.522.53
 3.0e-013.5e-014.0e-01Cosine distance (f)Volume ,w= 30 .
0.511.522.53
 1.5e-012.0e-012.5e-013.0e-01Cosine distance (g)Taxi,w= 30 .
0.511.522.53
 1.5e-012.0e-012.5e-013.0e-01Cosine distance (h)Power ,w= 30 .
0.511.522.53
 3.0e-013.5e-014.0e-01Cosine distance
(i)C6H6 ,w= 50 .
0.511.522.53
 3.0e-013.5e-014.0e-01Cosine distance (j)Volume ,w= 50 .
0.511.522.53
 1.5e-012.0e-012.5e-013.0e-01Cosine distance (k)Taxi,w= 50 .
0.511.522.53
 1.5e-012.0e-012.5e-013.0e-01Cosine distance (l)Power ,w= 50 .
Fig. 5: Cosine distance comparison w.r.t. ϵfor perturbation parameterization algorithms vs SW-direct
best experimental results, which can be attributed to select-
ing a more suitable range for the input values. Under ex-
tremely limited privacy budgets, we reduce the mechanism’s
sensitivity by clipping the input values to a smaller range
and normalizing them, thereby producing perturbed values
with better distinguishability. This superior performance is
consistent across different window sizes w, as shown in
Figures 4 (b), (f), and (j).
It is worth noting that in Figures 4 (d), (h), and (l), the
BA-SW algorithm performs best on the Power dataset when
ϵis relatively large. This is because many subsequences
in the Power dataset are entirely composed of a unique
constant value. BA-SW effectively identifies points with
minimal variation and directly reuses previous values. By
conserving the privacy budget, it introduces less noise,
thereby improving the utility of subsequent uploads.
2) The results for stream data publication: In Figure 5,
the basic setup is the same as that in Figure 4. We then
compare the cosine distance for different algorithms, where
a smaller cosine distance indicates that the estimated data
stream is closer to the ground truth.
We can see that the SW-direct’s cosine distance is the
largest compared to our perturbation parameterization algo-
rithms, indicating the worst performance. This is because
our algorithms utilize the perturbation of previous data to
reduce errors. We can see that CAPP demonstrates the
best performance among the perturbation parameterization
algorithms. This is because the method uses perturbation
information and sets an appropriate [l, u], further expanding
the advantage. It is noteworthy that for C6H6 , the utility of
CAPP increases when ϵincreases. This is because the designofl, uconsiders the worst case scenario, which may lead to
improper selection of T(ep,ed)in Equation 11 for different
datasets. However, we can still see that CAPP achieves better
utility than IPP and APP. In addition, we observe that IPP
is slightly better than APP for stream data publication. This
is because APP is influenced by multiple data points, which
may result in poor estimates of the true characteristics of
the data stream. In fact, APP is more suitable for mean
estimation, as can be seen in Figure 4. In contrast, IPP
preserves the information of individual data points better
and thus achieves better utility than APP for stream data
publication.
Similarly, our approaches maintain their superior perfor-
mance across different datasets under the same parameter
settings, as shown in Figures 5 (a)-(d), (e)-(h), and (i)-(l).
Observing the varied wvalues specific to each dataset, as
illustrated in Figures 5 (a), (e), and (i), it becomes clear
that our perturbation parameterization algorithms sustain
commendable performance across different wconfigura-
tions. This demonstrates the robustness of our perturbation
parameterization algorithms.
C. Overall Results for Sampling
1) The results for mean estimation: In this group of ex-
periments, we compare different parameters across datasets,
including the query length q, window size w, and privacy
budget ϵ. To ensure the stability of mean estimation results,
we randomly select 50 subsequences with length qand
average them.
As shown in Figures 6, when qandware fixed, the MSE
decreases for all algorithms as the privacy budget increases.
Among them, sampling performs the worst because it only
uploads information from sampled points. However, APP-S
and CAPP-S outperform other non-sampling methods. This
experiment demonstrates that our perturbation parameteriza-
tion algorithms retain their advantage even with sampling,
showcasing their superiority across different datasets and
various wandqcombinations.
2) The results for stream data publication: In Figure 7,
we evaluate the performance of stream data publication by
comparing the cosine distance between sampling and non-
sampling algorithms. The results reveal different patterns
from those observed in mean estimation (Figure 6). While
sampling algorithms demonstrate significant advantages in
mean estimation, they achieve similar performance levels
in stream data publication. This pattern difference can
be attributed to the reduced number of collecting values
in each window due to sampling, which affects the two
tasks differently: it helps reduce noise in mean estimation
while still maintaining sufficient information for stream data
publication. As illustrated in both figures, sampling-based
algorithms perform well in mean estimation. While their
performance in stream data publication is not as strong as
CAPP, they still outperform APP.
D. Discussion on Generalizability
1) The results for crowd-level statistics: We extend our
analysis from individual-level statistics to crowd-level statis-
tics, as shown in Figure 8. The evaluation metric used
is the Wasserstein distance between two distributions: the
estimated distribution and the true distribution of means
calculated from population subsequences. Figures 8 (a)-(d)
present the results without sampling techniques. Among the
methods, BA-SW performs the worst, followed by SW-
direct, whereas CAPP outperforms APP and IPP. With
sampling techniques (Figures 8 (e)-(h)), CAPP-S achieves
the best performance, followed by APP-S, highlighting the
synergy between our proposed methods and sampling. These
results indicate that our methods not only provide accurate
user-level time series statistics but also excel in estimating
crowd-level statistics.
2) Generalizability to different mechanisms: We replace
the SW mechanism with alternative numerical mechanisms
(Laplace, SR, and PM), and the results are presented in
Figure 9. The results demonstrate that our APP scheme
consistently enhances performance across all mechanisms in
both mean estimation and stream publication tasks. Notably,
the SW mechanism demonstrates superior performance com-
pared to all other mechanisms. This advantage arises from
its bounded perturbation range of ( −1
2,1
2), which preserves
a substantial amount of information during the clipping
process, irrespective of the ϵvalue. In contrast, other mech-
anisms either sacrifice excessive information due to their
broad perturbation domains or inherently discard significant
data characteristics during their perturbation processes, as
thoroughly analyzed in Section IV .C.
3) The results for high-dimensional time series: We ex-
tend our method to the analysis of high-dimensional timeseries. To evaluate its performance, we generate two datasets
with d= 5 andd= 12 dimensions, where each dimen-
sion follows a sinusoidal function with varying frequency
parameters. We process each dimension of the time series
independently, applying privacy-preserving mechanisms sep-
arately to each one. To address the privacy budget con-
straints in this high-dimensional setting, we implement two
strategies: Budget-Split (BS) and Sample-Split (SS). Figure
10 indicates that, while SW-SS and SW-BS perform the
worst within their respective strategies, our APP and CAPP
schemes significantly enhance the performance of both BS
and SS approaches. However, the BS strategies (SW-BS,
APP-BS, and CAPP-BS) outperform the SS strategies (SW-
SS, APP-SS, and CAPP-SS), primarily because the SS
approach suffers from reduced effectiveness caused by the
limited number of data points per window introduced by
sampling. This negative impact of sampling outweighs the
disadvantages associated with splitting the privacy budget.
4) Sensitivity analysis on [l, u]:We represent landu
using δ(where l= 0−δandu= 1 + δ), and evaluate
performance for different δvalues across four datasets:
Constant (a time series with a constant value of x= 0.1),
Pulse (zeros with a value of 1 inserted every five points),
Sinusoidal (generated according to a sin(x) distribution), and
C6H6 . The experimental results, as shown in Figure 11,
reveal consistent trends across all datasets: MSE decreases
asϵincreases. For a fixed ϵ, MSE follows a U-shaped curve
asδvaries from −1to0.5, with the optimal δ(corresponding
to the minimum MSE) differing across ϵvalues. Generally,
smaller ϵvalues are associated with larger optimal δvalues.
The MSE remains relatively stable in the vicinity of these
optimal δvalues. The recommended δvalues (marked with
stars), derived from Equation 11, are close to these optimal
values and fall within regions of stable MSE. We recommend
setting δwithin the range −0.25≤δ≤0.25, regardless of
the original data distribution. For larger ϵvalues, smaller δ
values are preferable, whereas for smaller ϵvalues, larger δ
values are recommended.
VII. R ELATED WORK
Local Differential Privacy (LDP) [3], [6], [16] is an ex-
tension of Differential Privacy (DP) [8], [9], [22] tailored for
individual users in distributed systems. LDP enables statis-
tical analysis across data types, supporting mean, frequency,
and distribution estimations. Within LDP, two primary pri-
vacy protection approaches exist: event-level [31] and user-
level [1]. However, event-level LDP provides insufficient
stream protection, while user-level LDP compromises utility
through privacy budget partitioning. The w-event LDP [32]
bridges this gap, offering a balanced framework for time
series data protection.
Several methods address streaming data under user-level
LDP, primarily focusing on discrete data collection [10],
[14], [33]. These approaches track statistical information by
monitoring data changes to manage privacy budget consump-
tion effectively. Specifically, [14] proposes a method that
efficiently controls individual user contributions when the
1/4 1/2 1 3/2 2 1/4 1/2 1 3/20.350.360.370.380.390.40.410.420.43SW-direct APP CAPP Sampling APP-S CAPP-S
0.511.522.53
 3.0e-024.0e-025.0e-026.0e-027.0e-02MSE(a)Volume ,w= 20, q= 10 .
0.511.522.53
 3.0e-024.0e-025.0e-026.0e-027.0e-02MSE (b)Volume ,w= 30, q= 10 .
0.511.522.53
 1.0e-021.5e-022.0e-02MSE (c)Volume ,w= 30, q= 20 .
0.511.522.53
 1.0e-031.0e-02MSE (d)Volume ,,w= 30, q= 40 .
0.511.522.53
 1.0e-031.0e-02MSE
(e)Volume ,w= 20, q= 30 .
0.511.522.53
 6.0e-028.0e-021.0e-011.2e-011.4e-01MSE (f)C6H6 ,w= 20, q= 30 .
0.511.522.53
 5.0e-021.0e-011.5e-01MSE (g)Power ,w= 20, q= 30 .
0.511.522.53
 2.0e-024.0e-026.0e-028.0e-021.0e-01MSE (h)Taxi,w= 20, q= 30 .
Fig. 6: MSE comparison w.r.t. ϵfor sampling-based algorithms vs non-sampling algorithms
1/4 1/2 1 3/2 2 1/4 1/2 1 3/20.350.360.370.380.390.40.410.420.43SW-direct APP CAPP Sampling APP-S CAPP-S
0.511.522.53
 2.0e-012.5e-013.0e-013.5e-014.0e-01JSD
(a)Volume ,w= 20, q= 10 .
0.511.522.53
 2.0e-012.5e-013.0e-013.5e-014.0e-01JSD (b)Volume ,w= 30, q= 10 .
0.511.522.53
 2.0e-012.5e-013.0e-013.5e-014.0e-01JSD (c)Volume ,w= 30, q= 20 .
0.511.522.53
 1.5e-012.0e-012.5e-01JSD (d)Volume ,,w= 30, q= 40 .
0.511.522.53
 1.5e-012.0e-012.5e-01JSD
(e)Volume ,w= 20, q= 30 .
0.511.522.53
 2.5e-013.0e-013.5e-014.0e-01JSD (f)C6H6 ,w= 20, q= 30 .
0.511.522.53
 4.5e-015.0e-015.5e-016.0e-01JSD (g)Power ,w= 20, q= 30 .
0.511.522.53
 1.0e-011.5e-012.0e-01JSD (h)Taxi,w= 20, q= 30 .
Fig. 7: Cosine Distance w.r.t. ϵfor sampling-based algorithms vs non-sampling algorithms
server’s previous estimation is accurate, thereby conserving
privacy budget. Erlingsson et al. [10] introduce a saniti-
zation and reporting mechanism for continuous frequency
estimation, where each user’s value can change at most
Ctimes with increments/decrements of ±1, and users ran-
domly report one of their Cchanges. [33] presents DDRM,
which employs binary trees to dynamically record tempo-
ral differences and suppresses privacy budget consumption
during periods of data stability, taking advantage of the
common occurrence of unchanged values in time series data.
However, these methods are designed for discrete time series
data and cannot be directly applied to continuous time series,
which is the focus of our study.
In this paper, we address two types of tasks. The first
type focuses on estimating individual-level statistics. Notable
existing works include ToPL [31], Pattern LDP [32], and
PrivShape [21]. ToPL [31] adopts event-level LDP con-
straints, which necessitate small privacy budgets for each
timestamp, ultimately compromising utility in stream datapublication. Pattern LDP [32] attempts to enhance utility
by transmitting only significant changes with increased per-
point privacy budgets, but this approach risks privacy leakage
through the exposure of change points. PrivShape [21] only
records key nodes, which may result in information loss
when queried intervals contain few or no key nodes. Our
work explores w-event level analysis as a balanced compro-
mise between these extremes. The second type focuses on
estimating statistical characteristics in crowd-level statistics.
As demonstrated in LDP-IDS [24], this includes analyzing
the distribution of population means. This method builds
upon the BA [17] concept of utilizing general privacy
budgets by not uploading points with minimal changes,
thus conserving remaining privacy budgets. Additionally, it
implements a sampling policy where users can upload their
information in discontinuous windows, avoiding privacy
budget splitting. Beyond simple time series, trajectory data
represents a more complex form of time series, as explored
in [17], [35], and [28]. These works maintain high utility
0.511.522.531.2e-011.3e-011.4e-011.5e-011.6e-01MSESW-direct BA-SW IPP APP CAPP
0.511.522.53
 4.0e+005.0e+006.0e+00Wasserstein distance(a)Taxi,w=q= 10 .
0.511.522.53
 2.5e+003.0e+003.5e+004.0e+004.5e+00Wasserstein distance (b)Taxi,w=q= 30 .
0.511.522.53
 3.0e+004.0e+005.0e+006.0e+00Wasserstein distance (c)Power ,w=q= 10 .
0.511.522.53
 2.0e+002.5e+003.0e+00Wasserstein distance (d)Power ,w=q= 30 .
1/4 1/2 1 3/2 2 1/4 1/2 1 3/20.350.360.370.380.390.40.410.420.43SW-direct APP CAPP Sampling APP-S CAPP-S
0.511.522.53
 6.0e-028.0e-021.0e-011.2e-01Wasserstein distance
(e)Taxi,w= 20, q= 10 .
0.511.522.53
 2.0e-024.0e-026.0e-028.0e-021.0e-01Wasserstein distance (f)Taxi,w= 20, q= 30 .
0.511.522.53
 6.0e-028.0e-021.0e-011.2e-01Wasserstein distance (g)Taxi,w= 30, q= 10 .
0.511.522.53
 1.0e-021.0e-01Wasserstein distance (h)Taxi,w= 30, q= 40 .
Fig. 8: Wasserstein distance comparison of user mean distributions w.r.t. ϵ
Laplace-direct Laplace-APP SR-direct SR-APP PM-direct PM-APP SW-direct SW-APP
0.511.522.531.0e+001.0e+02MSE
(a)C6H6 , MSE.
0.511.522.53
 1.0e-021.0e+001.0e+02MSE (b)Volume , MSE.
9.0e-019.2e-019.4e-01
0.5 1 1.5 2 2.5 32.7e-012.7e-012.8e-01Cosine distance (c)C6H6 , JSD.
7.5e-018.0e-018.5e-019.0e-019.5e-01
0.5 1 1.5 2 2.5 32.4e-012.5e-01Cosine distance (d)Volume , JSD.
Fig. 9: Performance comparison of different LDP mechanisms with APP (Laplace, SR, PM, and SW)
0.511.522.539.7e-019.7e-01Cosine distanceSW-BS APP-BS CAPP-BS SW-SS APP-SS CAPP-SS
0.511.522.53
 4.0e-025.0e-026.0e-027.0e-028.0e-02MSE
(a)Sin-data , MSE, d= 5.
0.511.522.53
 4.0e-026.0e-028.0e-021.0e-011.2e-01MSE (b)Sin-data , MSE, d= 10 .
0.511.522.53
 1.5e-012.0e-012.5e-013.0e-01Cosine distance (c)Sin-data , JSD, d= 5.
0.511.522.53
 1.5e-012.0e-012.5e-013.0e-013.5e-01Cosine distance (d)Sin-data , JSD, d= 10 .
Fig. 10: Performance comparison of budget-split and sample-split in high-dimensional data
while satisfying local differential privacy requirements.
VIII. C ONCLUSIONS
In this paper, we propose novel algorithms to collect and
publish stream data under LDP. By effectively utilizing per-
turbations in two complementary ways, our methods signif-
icantly enhance utility compared to existing approaches. We
present the IPP, APP, and CAPP algorithms and prove they
satisfy w-event differential privacy. Moreover, we devise an
optimized sampling scheme, further improving the accuracy
of subsequence mean statistics. Experiments demonstrate
the effectiveness of our techniques. This research opens
a new direction for high-utility stream data analysis withprivacy guarantees. Future work could extend this approach
to handle more data types and apply it to emerging contexts
like IoT and edge computing.
ACKNOWLEDGEMENTS
This work was supported by the National Natural Science
Foundation of China (Grant No: 62372122 and 92270123),
and the Research Grants Council, Hong Kong SAR, China
(Grant No: 15203120, 15225921, 15209922, and 15224124).
REFERENCES
[1] Ergute Bao, Yin Yang, Xiaokui Xiao, and Bolin Ding. Cgm: an en-
hanced mechanism for streaming data collection with local differential
-1 -0.5 0 0.500.010.020.030.040.050.060.07=0.5
=1=1.5
=2=2.5
=3=3.5
=4=4.5
=5
-1 -0.5 0 0.50.10.20.30.40.5MSE(a)Constant .
-1 -0.5 0 0.50.10.20.30.4MSE (b)Pulse , MSE, d= 10 .
-1 -0.5 0 0.50.10.20.30.4MSE (c)Sinusoidal .
-1 -0.5 0 0.50.10.20.30.4MSE (d)C6H6 .
Fig. 11: Sensitivity analysis of δon MSE across datasets, w=q= 10
privacy. Proceedings of the VLDB Endowment , 14(11):2258–2270,
2021.
[2] Eric Booth, Jeff Mount, and Joshua H Viers. Hydrologic variability of
the cosumnes river floodplain. San Francisco Estuary and Watershed
Science , 4(2), 2006.
[3] Rui Chen, Haoran Li, A Kai Qin, Shiva Prasad Kasiviswanathan, and
Hongxia Jin. Private spatial data aggregation in the local setting.
In2016 IEEE 32nd International Conference on Data Engineering
(ICDE) , pages 289–300. IEEE, 2016.
[4] Bolin Ding, Janardhan Kulkarni, and Sergey Yekhanin. Collecting
telemetry data privately. arXiv preprint arXiv:1712.01524 , 2017.
[5] Dawn W Dowding, Marianne Turley, and Terhilda Garrido. The
impact of an electronic health record on nurse sensitive patient
outcomes: an interrupted time series analysis. Journal of the American
Medical Informatics Association , 19(4):615–620, 2012.
[6] John C Duchi, Michael I Jordan, and Martin J Wainwright. Local
privacy, data processing inequalities, and statistical minimax rates.
arXiv preprint arXiv:1302.3203 , 2013.
[7] John C Duchi, Michael I Jordan, and Martin J Wainwright. Minimax
optimal procedures for locally private estimation. Journal of the
American Statistical Association , 113(521):182–201, 2018.
[8] Cynthia Dwork. Differential privacy: A survey of results. In
International conference on theory and applications of models of
computation , pages 1–19. Springer, 2008.
[9] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith.
Calibrating noise to sensitivity in private data analysis. In Theory of
cryptography conference , pages 265–284. Springer, 2006.
[10] ´Ulfar Erlingsson, Vitaly Feldman, Ilya Mironov, Ananth Raghunathan,
Kunal Talwar, and Abhradeep Thakurta. Amplification by shuffling:
From local to central differential privacy via anonymity. In Pro-
ceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete
Algorithms , pages 2468–2479. SIAM, 2019.
[11] ´Ulfar Erlingsson, Vasyl Pihur, and Aleksandra Korolova. Rappor:
Randomized aggregatable privacy-preserving ordinal response. In
Proceedings of the 2014 ACM SIGSAC conference on computer and
communications security , pages 1054–1067, 2014.
[12] Ma Janice J Gumasing, Frances Jeann Charlize S Bermejo, Keisha
Taranee C Elpedes, Lady Fatima E Gonzales, and Aaron Chastine V
Villajin. Antecedents of waze mobile application usage as a solution
for sustainable traffic management among gen z. 2023.
[13] AR Harris. Time series remote sensing of a climatically sensitive
lake. Remote Sensing of Environment , 50(2):83–94, 1994.
[14] Matthew Joseph, Aaron Roth, Jonathan Ullman, and Bo Waggoner.
Local differential privacy for evolving data. Advances in Neural
Information Processing Systems , 31, 2018.
[15] James Joyce. Bayes’ theorem. 2003.
[16] Shiva Prasad Kasiviswanathan, Homin K Lee, Kobbi Nissim, Sofya
Raskhodnikova, and Adam Smith. What can we learn privately? SIAM
Journal on Computing , 40(3):793–826, 2011.
[17] Georgios Kellaris, Stavros Papadopoulos, Xiaokui Xiao, and Dimitris
Papadias. Differentially private event sequences over infinite streams.
Proceedings of the VLDB Endowment , 7(12):1155–1166, 2014.
[18] Erich L Lehmann and George Casella. Theory of point estimation .
Springer Science & Business Media, 2006.
[19] Ninghui Li, Min Lyu, Dong Su, and Weining Yang. Differential
privacy: From theory to practice. Synthesis Lectures on Information
Security, Privacy, & Trust , 8(4):1–138, 2016.
[20] Zitao Li, Tianhao Wang, Milan Lopuha ¨a-Zwakenberg, Ninghui Li,
and Boris ˇSkoric. Estimating numerical distributions under localdifferential privacy. In Proceedings of the 2020 ACM SIGMOD
International Conference on Management of Data , pages 621–635,
2020.
[21] Yulian Mao, Qingqing Ye, Haibo Hu, Qi Wang, and Kai Huang.
Privshape: Extracting shapes in time series under user-level local
differential privacy. arXiv preprint arXiv:2404.03873 , 2024.
[22] Frank McSherry and Kunal Talwar. Mechanism design via differential
privacy. In 48th Annual IEEE Symposium on Foundations of Computer
Science (FOCS’07) , pages 94–103. IEEE, 2007.
[23] A Pranklin. Introduction to the Theory of Statistics . 1974.
[24] Xuebin Ren, Liang Shi, Weiren Yu, Shusen Yang, Cong Zhao, and
Zongben Xu. Ldp-ids: Local differential privacy for infinite data
streams. In Proceedings of the 2022 international conference on
management of data , pages 1064–1077, 2022.
[25] Richard J Rossi. Mathematical statistics: an introduction to likelihood
based inference . John Wiley & Sons, 2018.
[26] Ludger R ¨uschendorf. The wasserstein distance and approximation
theorems. Probability Theory & Related Fields , 70(1):117–129, 1985.
[27] Amit Singhal et al. Modern information retrieval: A brief overview.
IEEE Data Eng. Bull. , 24(4):35–43, 2001.
[28] Xinyue Sun, Qingqing Ye, Haibo Hu, Yuandong Wang, Kai Huang,
Tianyu Wo, and Jie Xu. Synthesizing realistic trajectory data with
differential privacy. IEEE Transactions on Intelligent Transportation
Systems , 24(5):5502–5515, 2023.
[29] ADP Team et al. Learning with privacy at scale. Apple Mach. Learn.
J, 1(8):1–25, 2017.
[30] Ning Wang, Xiaokui Xiao, Yin Yang, Jun Zhao, Siu Cheung Hui,
Hyejin Shin, Junbum Shin, and Ge Yu. Collecting and analyzing
multidimensional data with local differential privacy. In 2019 IEEE
35th International Conference on Data Engineering (ICDE) , pages
638–649. IEEE, 2019.
[31] Tianhao Wang, Joann Qiongna Chen, Zhikun Zhang, Dong Su,
Yueqiang Cheng, Zhou Li, Ninghui Li, and Somesh Jha. Continuous
release of data streams under both centralized and local differential
privacy. In Proceedings of the 2021 ACM SIGSAC Conference on
Computer and Communications Security , pages 1237–1253, 2021.
[32] Zhibo Wang, Wenxin Liu, Xiaoyi Pang, Ju Ren, Zhe Liu, and
Yongle Chen. Towards pattern-aware privacy-preserving real-time data
collection. In IEEE INFOCOM 2020-IEEE Conference on Computer
Communications , pages 109–118. IEEE, 2020.
[33] Qiao Xue, Qingqing Ye, Haibo Hu, Youwen Zhu, and Jian Wang.
Ddrm: A continual frequency estimation mechanism with local dif-
ferential privacy. IEEE Transactions on Knowledge and Data Engi-
neering , 35(7):6784–6797, 2022.
[34] Mengxia Zhang and Lan Luo. Can consumer-posted photos serve
as a leading indicator of restaurant survival? evidence from yelp.
Management Science , 69(1):25–50, 2023.
[35] Yuemin Zhang, Qingqing Ye, Rui Chen, Haibo Hu, and Qilong
Han. Trajectory data collection with local differential privacy. arXiv
preprint arXiv:2307.09339 , 2023.