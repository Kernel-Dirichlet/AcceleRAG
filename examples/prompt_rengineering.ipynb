{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adb5f576-be96-4c7e-bfa5-48df4cc112bf",
   "metadata": {},
   "source": [
    "## PROMPT REENGINEERING \n",
    "\n",
    "#### This notebook showcases how we can replicate familar prompt engineering with the new taxonomy proposed in this repo. \n",
    "#### The first nine sections are more established prompts which we replicate with ThoughtActions or chains-thereof \n",
    "#### Sections 10-12 are extensions of the first ten which can be achieved by leveraging the \"ThoughtAction\" abstractions that are the core unit of the CoTAEngine. Note that we skip Retrieval-Augmented Generation (RAG). This is handled by the AcceleRAG engine, and merits its own notebook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60cae15-0a0a-4acf-822d-6a487e137b58",
   "metadata": {},
   "source": [
    "## TOC\n",
    "   1) *I/O prompting*\n",
    "   2) *Prompt templating*\n",
    "   3) *ReACT prompting*\n",
    "   4) *Few-shot prompting*\n",
    "   5) *Program-aided Language (PAL)*\n",
    "   6) *Chain-of-Thought (CoT)*\n",
    "   7) *Chain-of-thought w/self-consistency (CoT-SC)*\n",
    "   8) *Tree-of-thoughts (ToT) & Graph-of-thoughts (GoT)*\n",
    "   9) *Automated Prompt Engineering (APE) & Meta-prompting*\n",
    "   10) **Iterative Thought-Actions**\n",
    "   11) **Recursive Thought-Actions**\n",
    "   12) **Meta-CoT**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b25622-bb8f-461d-bc71-72e83774b6f4",
   "metadata": {},
   "source": [
    "### Getting started & tips\n",
    "\n",
    "#### The examples below like to use python dictionaries / JSON-like objects to encourage the reader to consider how to use RESTful APIs w/ ThoughtActions. This is not a hard requirement, as CoTARAG does not enforce non-essential design patterns onto the user.\n",
    "\n",
    "#### This notebook is designed so that the user interacts with it. Yes, it is somewhat chaotic, but as of 6/6/2025, this entire repo to date was written by one person, so if you want improvements, file an issue. \n",
    "\n",
    "#### That said, RESTful APIs make debugging easier than it already is. Ease of debugging is a must have for any production environments. \n",
    "\n",
    "#### ThoughtAction subclasses implement the __call__ method, so subclasses can be used in a functional programming style. Additionally, the __call__ method *verifies* both the thought and the action method actually return something (they cannot be None, and this is a sensible design choice). If you *must* go out of pocket, you can simply override the __call__ method to not do that. \n",
    "\n",
    "#### For now, think of a ThoughtAction as an abstraction / generalization of the ReACT prompt strategy. We will see how it is more expressive. \n",
    "\n",
    "#### *Design note* CoTARAG could have just as easily chosen CoAT over CoTA (Chain-of-action-thought vs. Chain-of-thought-action). This is mostly convention, but is far easier to reason about cause and effect by thinking how humans naturally operate. First there is a thought, and then there is an action. Of course, anyone is free to invert this operation as they see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54bbe42a-36e7-4789-b7b0-18bb55bf89af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boole/shannon_backup/AcceleRAG/cotarag_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import sys \n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "from contextlib import redirect_stdout\n",
    "from cotarag.accelerag.query_engines import AnthropicEngine, OpenAIEngine\n",
    "from cotarag.cota_engine.thought_actions import ThoughtAction,LLMThoughtAction, IterativeThoughtAction \n",
    "from cotarag.cota_engine.cota_engines import CoTAEngine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43dc33d5-0503-4721-8703-139043e66a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "type 1 if you want to use the OpenAI QueryEngine (GPT-4o) or 2 for Anthropic (Claude-3.7 Sonnet) 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAIEngine(api_key=None)\n"
     ]
    }
   ],
   "source": [
    "os.environ['CLAUDE_API_KEY'] = \"\" #place your Anthropic API keys her\n",
    "os.environ['OPENAI_API_KEY'] = \"\" #place your OpenAPI key here\n",
    "\n",
    "OPENAI_QUERY_ENGINE = OpenAIEngine(api_key = os.environ['OPENAI_API_KEY'])\n",
    "ANTHROPIC_QUERY_ENGINE = AnthropicEngine(api_key = os.environ['CLAUDE_API_KEY']) \n",
    "\n",
    "choice = input(\"type 1 if you want to use the OpenAI QueryEngine (GPT-4o) or 2 for Anthropic (Claude-3.7 Sonnet)\")\n",
    "if int(choice) == 1:\n",
    "    QUERY_ENGINE = OPENAI_QUERY_ENGINE\n",
    "else:\n",
    "    QUERY_ENGINE = ANTHROPIC_QUERY_ENGINE\n",
    "print(QUERY_ENGINE)\n",
    "\n",
    "#For those who have read the README, you can make your own QueryEngine class, but this notebook so far only works with the AnthropicEngine or OpenAIEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938f6577-7806-46c0-8f14-d08259950434",
   "metadata": {},
   "source": [
    "## 1) I/O prompting\n",
    "\n",
    "\n",
    "##### This is the most basic prompt. We enter in text to an LLM and then it answers back, hence the name, input/output prompting. This is the simplest prompt feedback loop. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2951765-1e57-4551-aef0-121eb2235f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wyoming's history is rich and varied, reflecting its Native American heritage, exploration by European settlers, and its development as a U.S. state.\n",
      "\n",
      "1. **Native American Presence**: Before European contact, Wyoming was inhabited by various Native American tribes, including the Arapaho, Crow, Lakota, and Shoshone. These tribes lived off the land as hunters and gatherers, with complex cultures and trade networks.\n",
      "\n",
      "2. **European Exploration and Fur Trade (Early 19th Century)**: The early 1800s saw European-American exploration, with figures like John Colter, a member of the Lewis and Clark Expedition, being among the first to document the region. The area became a hub for the fur trade, attracting trappers and traders.\n",
      "\n",
      "3. **Westward Expansion and Settlers (Mid-19th Century)**: The Oregon Trail, which passed through Wyoming, brought many settlers westward. Fort Laramie became a significant stop for pioneers. The discovery of gold in the surrounding regions also spurred movement through Wyoming.\n",
      "\n",
      "4. **Territorial Days (1868-1890)**: Wyoming became a U.S. territory in 1868. During this period, the Union Pacific Railroad reached the area, facilitating further settlement and economic development.\n",
      "\n",
      "5. **Womenâ€™s Suffrage (1869)**: Wyoming made history by granting women the right to vote in 1869, becoming the first U.S. territory and later the first state to do so. This earned it the nickname \"The Equality State.\"\n",
      "\n",
      "6. **Statehood (1890)**: Wyoming was admitted to the Union as the 44th state on July 10, 1890. The state's economy was largely based on agriculture, mining, and livestock.\n",
      "\n",
      "7. **20th Century Developments**: Wyoming continued to grow through the 20th century, with developments in coal, oil, and natural gas industries. Tourism also became significant, with attractions like Yellowstone National Park drawing visitors.\n",
      "\n",
      "8. **Modern Era**: Today, Wyoming remains one of the least populous states, known for its vast open spaces, natural beauty, and significant energy resources. Its economy is driven by mining, tourism, and agriculture, maintaining its frontier spirit while embracing modern advancements.\n",
      "\n",
      "Throughout its history, Wyoming has been characterized by its rugged landscapes, pioneering spirit, and commitment to equality, particularly regarding women's rights.\n"
     ]
    }
   ],
   "source": [
    "class IOPrompt(LLMThoughtAction):\n",
    "    \"\"\"\n",
    "    Simple I/O Prompting Pattern\n",
    "    \n",
    "    This is the most basic pattern where:\n",
    "    - Thought: Just passes through the query\n",
    "    - Action: Just returns the LLM's response (a \"no-op\") \n",
    "    \"\"\"\n",
    "    \n",
    "    def thought(self, input_data):\n",
    "        # Reasoning: Simply return the query as the prompt\n",
    "        return input_data['query']\n",
    "        \n",
    "    def action(self, thought_output):\n",
    "        # Reasoning: Just return the LLM's response\n",
    "        return {\n",
    "            'response': self.query_engine.generate_response(thought_output)\n",
    "        }\n",
    "\n",
    "io_prompt_engine = IOPrompt(query_engine = QUERY_ENGINE)\n",
    "input_data = {'query': 'Summarize the history of Wyoming'}\n",
    "\n",
    "result = io_prompt_engine(input_data)['response'] \n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88005f82-f993-4464-91c8-18601e5f6105",
   "metadata": {},
   "source": [
    "## 2) Prompt Templates \n",
    "\n",
    "### How many r's in \"strawberry\"? \n",
    "\n",
    "##### Here, we take a string and parameterize it, then feed it into an LLM. The string that is actually passed to the LLM will vary based on parameters passed to it, rather than a simple, fixed string we saw above w/ I/O prompting. \n",
    "\n",
    "##### Many in the AI space know the infamous previous failure of ChatGPT to accurately count the number of r's in the word \"strawberry\". We will show how since we obviously don't need an LLM to answer the question, we can just use an ordinary ThoughtAction. In a more advanced pipeline, it may make sense to use a ThoughtAction (or multiple) at some intermediate stage where we cannot afford LLM hallucinations.  \n",
    "\n",
    "##### When interacting with a LLM-powered chatbot, the end user does not see *how* the chatbot arrived at its response, only the response itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a14edc3-7e90-453f-9558-05b81282bfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: the number of r's in the word strawberry is 3\n"
     ]
    }
   ],
   "source": [
    "query_template = \"How many letters {letter} are in the word {word}\"\n",
    "\n",
    "input_data = {'query': query_template,\n",
    "              'letter': 'r',\n",
    "              'word': 'strawberry'} #feel free to modify this dictionary to become more familiar with the API for ThoughtActions \n",
    "\n",
    "class PromptTemplate(ThoughtAction):\n",
    "\n",
    "    def __init__(self,\n",
    "                verbose = True):\n",
    "        if verbose:\n",
    "            self.verbose = True\n",
    "        else:\n",
    "            self.verbose = False\n",
    "        pass\n",
    "\n",
    "    def thought(self,\n",
    "                input_data):\n",
    "\n",
    "        '''\n",
    "        Here, you can modify a prompt based on any program logic you can write.\n",
    "        Note that you can parse strings and perform additional string operations here.  \n",
    "\n",
    "        '''\n",
    "        letter = input_data['letter']\n",
    "        word = input_data['word'] \n",
    "        self.query = input_data['query'] #store as attribute to reuse in the action method if needed \n",
    "        prompt = self.query.format(letter = letter,\n",
    "                              word = word)\n",
    "        thought = \"the number of {}'s in the word {} is {}\".format(letter,word,word.count(letter))\n",
    "        return {'thought': thought} #Note the output here is dictionary formatted\n",
    "\n",
    "    def action(self,\n",
    "               thought_output):\n",
    "        \n",
    "        if self.verbose:\n",
    "            return {'action': thought_output}\n",
    "        else:\n",
    "            return thought_output['thought']\n",
    "\n",
    "        \n",
    "prompt_template_agent = PromptTemplate(verbose = False) \n",
    "result = prompt_template_agent(input_data = input_data)\n",
    "print(f\"output: {result}\")\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9109d0-1d3d-40c3-bafc-a52079c650e9",
   "metadata": {},
   "source": [
    "## 3) Reason-act (ReACT) prompting\n",
    "\n",
    "##### ReACT prompting is just a single LLMThoughtAction step, but with the specific restriction that the \"thought\" is restricted to just the input to the LLM rather than any external string/prompt processing, and the action is limited to just the LLM's output itself. This distinction is somewhat contrived and context dependent, but for the purposes of this notebook, this is the distinction made. \n",
    "\n",
    "##### In this example, we will have an LLMThoughtAction take a user question (the thought), and then format the output and show the user (the action) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1db7f00-c4b1-4dbe-bd01-fa9f673a842d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'LLM: OpenAIEngine(api_key=********)\\nCertainly! Here are three fun facts about bananas:\\n\\n1. **Naturally Radioactive**: Bananas are slightly radioactive due to their high potassium content. They contain a small amount of potassium-40, a naturally occurring isotope that is radioactive. However, the level of radioactivity is extremely low and completely harmless to humans. This property even led to the creation of the \"Banana Equivalent Dose,\" a humorous unit of radiation exposure.\\n\\n2. **Bananas Are Berries**: Botanically speaking, bananas are classified as berries. In botanical terms, a berry is a fruit produced from the ovary of a single flower with seeds embedded in the flesh. Bananas fit this definition, whereas fruits typically considered as berries, like strawberries and raspberries, do not.\\n\\n3. **Seedless Cultivation**: The bananas we commonly eat today are a result of selective breeding and are mostly seedless. The most popular variety, the Cavendish, is a triploid, meaning it has three sets of chromosomes and is sterile. This makes it unable to produce seeds, so new banana plants are propagated through cuttings from the parent plant rather than from seeds.'}\n"
     ]
    }
   ],
   "source": [
    "class ReACTFormatter(LLMThoughtAction):\n",
    "\n",
    "    def thought(self,input_data):\n",
    "        return {'thought': input_data} \n",
    "\n",
    "    def action(self,thought_input):\n",
    "\n",
    "        input_data = thought_input['thought']\n",
    "        self.query = input_data['query']\n",
    "        self.format = input_data['format']\n",
    "        response = self.query_engine.generate_response(self.query)\n",
    "        if self.format == 'verbose': \n",
    "            header = \"LLM: {}\\n\".format(str(self.query_engine))\n",
    "        else:\n",
    "            header = \"\\n\"\n",
    "        show_str = '{}{}'.format(header,response)\n",
    "        return {'action': show_str}\n",
    "\n",
    "query = \"tell me about three fun facts about bananas\"\n",
    "input_data = {'query': query,\n",
    "             'format': 'verbose'}\n",
    "\n",
    "formatter = ReACTFormatter(query_engine = QUERY_ENGINE)\n",
    "result = formatter(input_data)\n",
    "print(result) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3542b9d0-b2c4-42de-b1e0-bcf5b4234d0c",
   "metadata": {},
   "source": [
    "## 4) Few-shot prompting\n",
    "\n",
    "#### Zero-shot prompting is similar to I/O prompting, except that we typically describe how to do a task related to the output we want. The distinction between this and I/O prompting is blurry. An example would be describing a zebra as a \"horse but with black and white stripes all over\" to a multi-modal text/image generator. We rely on the model's pre-training in the zero-shot case. \n",
    "\n",
    "#### N-shot prompting is where we provide *explicit* examples in an input to help the LLM better understand what we want from the output. Expanding on the example above, this would be providing explicit pictures of zebras. Here is another example with text\n",
    "\n",
    "#### User: \n",
    "\n",
    "##### \"I want you to classify the following sentences as positive, negative or neutral and format the answer with the sentence, followed by a \":\", and then the sentiment. Examples are \n",
    "    1) \"This show rocks!\": Positive\n",
    "    2) \"This movie is trash!: Negative\n",
    "    3) \"This movie is okay: Neutral\" \n",
    "\n",
    "     {user places movies along with reviews here} \n",
    "##### LLM: ...\n",
    "\n",
    "##### Few-shot prompting is when N is typically between 1-5. If N was incredibly large, (ex. N > 100) we would be starting to blur the lines between few-shot prompting and full on LLM fine-tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10541b0a-d1e5-407b-8cad-156fd41f3270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'positive  \\nnegative'}\n"
     ]
    }
   ],
   "source": [
    "class FewShotPrompter(LLMThoughtAction):\n",
    "\n",
    "    def thought(self,input_data):\n",
    "        data = input_data['data']\n",
    "        query = input_data['query']\n",
    "        formatted_string = f\"Query: {query}\"\n",
    "        for i,sample in enumerate(data):\n",
    "            formatted_string += f'{i+1}\\n'\n",
    "            formatted_string += f\"show: {sample['show']} review: {sample['review']} \"\n",
    "        prompt = formatted_string\n",
    "        return {'thought': prompt}\n",
    "       \n",
    "    def action(self,thought_output):\n",
    "        response = self.query_engine.generate_response(json.dumps(thought_output))\n",
    "        return {'action': response} \n",
    "        \n",
    "\n",
    "header = \"\"\"\n",
    "        I want to classify TV show and movie sentiments into positive, neutral, and negative. \n",
    "        I will provide the title and the reviews and you will classify them. ONLY OUTPUT THE SENTIMENT AND NOTHING ELSE\n",
    "        Examples:\n",
    "            1) Mean Girls - an iconic movie capturing the essence of early 2000s culture: positive\n",
    "            2) Paul Blart, Mall Cop - a movie is right in the middle of the road: neutral \n",
    "            3) Grey's Anatomy - below mediocre acting, no plot progression: negative\n",
    "\n",
    "        Here are the shows and movies: \n",
    "        \"\"\"\n",
    "\n",
    "show1 = {\"show\": \"Breaking Bad\",\n",
    "            \"review\": \"this show was amazing\"}\n",
    "show2 = {\"show\": \"Game of Thrones\",\n",
    "            \"review\": \"this show is and was dramatically overhyped\"}\n",
    "\n",
    "shows = [show1,show2]\n",
    "\n",
    "few_shot_prompter = FewShotPrompter(query_engine = QUERY_ENGINE)\n",
    "result = few_shot_prompter(input_data = {\"query\": header,\"data\": shows})\n",
    "print(result)       \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e3f419-1b86-417a-806a-ac53f3fa2241",
   "metadata": {},
   "source": [
    "## Program-aided-Language (PAL) \n",
    "\n",
    "#### PAL is essentially where we input our query in plain text but the output \"thoughts\" are programs. Often times, examples of program snippets can be provided. The output is then a program which is to be executed. This can work well enough for simple python programs, but breaks down in languages with stronger type systems like Rust and Haskell, especially as the program complexity increases. \n",
    "\n",
    "#### An example of this can be found in the ml_pipeline notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f57e8e-feaf-418f-b912-b1c977d3d40d",
   "metadata": {},
   "source": [
    "## Chain-of-Thought (CoT)\n",
    "\n",
    "#### CoT can come in two flavors\n",
    "     1) user prompts the LLM to solve a problem, but break down the reasoning \"step-by-step\". There is one API call and the output is itself a CoT\n",
    "     2) The output of an LLM response feeds into itself (or another one) in a N-step chain. This ends up being N api calls. \n",
    "\n",
    "#### CoT is simply a CoTA where the action is a \"no-op\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0214719e-f714-45f1-85e4-787e4592cb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve the problem, we will break it down step-by-step:\n",
      "\n",
      "Step 1: Identify the initial number of apples Jackie has.\n",
      "- Jackie starts with 5 apples.\n",
      "\n",
      "Step 2: Calculate how many apples Jackie has after eating some.\n",
      "- Jackie eats 2 apples, so we subtract 2 from her initial 5 apples.\n",
      "- Calculation: 5 - 2 = 3 apples remaining.\n",
      "\n",
      "Step 3: Determine how many apples Jackie has after receiving more from Adam.\n",
      "- Adam gives Jackie 4 more apples.\n",
      "- Calculation: 3 + 4 = 7 apples.\n",
      "\n",
      "Step 4: Include the apples Jackie buys herself.\n",
      "- Jackie buys 1 more apple.\n",
      "- Calculation: 7 + 1 = 8 apples.\n",
      "\n",
      "Step 5: Conclude with the total number of apples Jackie has now.\n",
      "- Jackie now has a total of 8 apples.\n",
      "\n",
      "Hence, the final answer is that Jackie has 8 apples.\n"
     ]
    }
   ],
   "source": [
    "class ChainOfThought(LLMThoughtAction):\n",
    "\n",
    "    def thought(self,\n",
    "                query):\n",
    "\n",
    "        self.query = query \n",
    "        cot_header = \"\"\"break down your reasoning for all subsequent queries step-by-step, output your steps as a chain \n",
    "                     step 1 -> step 2 -> ... -> step N \\nQuery: \"\"\"\n",
    "        self.thought = f\"{cot_header}:{query}\"\n",
    "        return {'thought': self.thought}\n",
    "\n",
    "    def action(self,thought_input):\n",
    "        return {'action': self.query_engine.generate_response(thought_input['thought']),\n",
    "                'query': self.query,\n",
    "               'thought': self.thought}\n",
    "        \n",
    "cot = ChainOfThought(query_engine = QUERY_ENGINE)\n",
    "prompt = \"Jackie has 5 apples, she ate 2 of them. Adam then gave her 4 more. If she buys one more herself, how many apples does she have now?\"\n",
    "result = cot(prompt)\n",
    "print(result['action'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a328962a-17dc-401c-a909-a738638a6a8e",
   "metadata": {},
   "source": [
    "## Chain-of-Thought w/ self-consistency (CoT-SC)\n",
    "\n",
    "#### This is where we prompt the LLM to generate *multiple* reasoning chains. We input a query and get K reasoning chains. Note that each of the K reasoning chains do not necessarily need to have the same number of steps. We then treat each chain as an \"ensemble\", going on the observation that the correct answer will appear more often than not in a reasoning distribution. Errors tend to get more diverse and correct answers \"converge\".\n",
    "\n",
    "#### The same query is used between the CoT and CoT-SC examples for easier understanding. As we saw above, CoT (and CoT-SC) are ThoughtActions with the action being a \"no-op\". \n",
    "\n",
    "#### Astute readers probably have already noticed that most of the previous examples *also* are ThoughtActions with the action as a \"no-op\". The action can augment the prompt if the user adds in more logic. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0371c1e8-51ad-4b59-8cd3-105ae89b13d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning Chain 1:\n",
      "1. Jackie starts with 5 apples.\n",
      "2. She eats 2 apples, so she has 5 - 2 = 3 apples left.\n",
      "3. Adam gives her 4 more apples, so she now has 3 + 4 = 7 apples.\n",
      "4. Jackie buys one more apple herself, bringing her total to 7 + 1 = 8 apples.\n",
      "\n",
      "Reasoning Chain 2:\n",
      "1. Jackie initially has 5 apples.\n",
      "2. After eating 2 apples, she has 5 - 2 = 3 apples.\n",
      "3. Adam adds 4 apples to her current count, resulting in 3 + 4 = 7 apples.\n",
      "4. She purchases an additional apple, increasing her total to 7 + 1 = 8 apples.\n",
      "\n",
      "Reasoning Chain 3:\n",
      "1. Starting with 5 apples, Jackie eats 2, leaving her with 5 - 2 = 3 apples.\n",
      "2. Adam gives her an additional 4 apples, so she now has 3 + 4 = 7 apples.\n",
      "3. Jackie buys another apple, which adds up to 7 + 1 = 8 apples.\n",
      "\n",
      "Comparison:\n",
      "All three reasoning chains conclude that Jackie has 8 apples. Each chain follows a logical sequence of operations (subtracting, adding, and then adding again) to reach the solution. Therefore, the most frequently appearing and logically sound answer is that Jackie has 8 apples.\n"
     ]
    }
   ],
   "source": [
    "cot_sc_header = \"\"\"You are a careful and logical thinker\n",
    "        For the following query, generate multiple independent reasoning chains\n",
    "        (use {num_chains} in total) such that each chain is an attempt to answer the query correctly,\n",
    "        using different logical approaches or perspectives if possible.\n",
    "        \n",
    "        After generating all reasoning chains, compare the final answers and choose\n",
    "        the one that appears most frequently or is most logically sound.\n",
    "        Query: {query}\"\"\"\n",
    "\n",
    "class ChainOfThoughtSC(LLMThoughtAction):\n",
    "\n",
    "    def thought(self,\n",
    "                input_data,\n",
    "                num_chains = 3):\n",
    "        \n",
    "        query = input_data['query']\n",
    "        template = input_data['template']\n",
    "        thought = template.format(query = query,\n",
    "                                  num_chains = num_chains)\n",
    "        return {'thought': thought}\n",
    "        \n",
    "    def action(self,thought_output):\n",
    "        action = self.query_engine.generate_response(thought_output['thought'])\n",
    "        return {'action': action} \n",
    "        \n",
    "\n",
    "input_data = {'template': cot_sc_header,\n",
    "              'query': \"Jackie has 5 apples, she ate 2 of them. Adam then gave her 4 more. If she buys one more herself, how many apples does she have now?\"}\n",
    "\n",
    "\n",
    "cot_sc_prompter = ChainOfThoughtSC(query_engine = QUERY_ENGINE)\n",
    "results = cot_sc_prompter(input_data)\n",
    "print(results['action']) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d7d096-5ca1-48b0-bfb4-13ed33cefa2e",
   "metadata": {},
   "source": [
    "## Tree-of-Thoughts (ToT) & Graph-of-Thoughts (GoT) \n",
    "\n",
    "#### ToT is an extension of CoT and CoT-SC where the intermediate reasoning steps can branch out in a tree structure. Taking that idea further, we have Graph-of-thoughts (GoT) where the thoughts branch out in a more generic pattern. Note that this of course forms a DAG, and we can actually add weights to the edges. In this example, we will actually chain together LLMActions to form a CoTA. \n",
    "\n",
    "#### Design note: It is possible to make a Tree-of-thought-actions (ToTA) and a Graph-of-Thought-Actions (GoTA). This would increase code complexity, as modeling a workflow as a DAG mighht require debugging incoming and outgoing edges to all nodes. In a CoTA, we have a unidirectional chain. We can of course wrap a ToT or a GoT in a LLMThoughtAction (or several) and this way, we isolate the errors to one step of a larger pipeline. ToTA and GoTA will be added to the CoTARAG repository at a later date. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453a38bf-007c-4b91-ae98-c46794ee9350",
   "metadata": {},
   "source": [
    "## Automated Prompt Engineering (APE) & Meta-prompting \n",
    "\n",
    "#### APE is where we task an LLM to generate prompts (often more than one) to solve a given task, and is closely related to meta-prompting. For this example, we ask the reader to try their hand at implementing either of these two or both. This can be done w/ a single LLMThoughtAction where the \"thought\" is the initial query and goal and the \"action\" is a refinement step. If doing APE, consider generating multiple candidate prompts, with each one being generated with slightly different logic. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419aaa9f-93c0-4b72-a227-344bd1784d78",
   "metadata": {},
   "source": [
    "## Iterative ThoughtActions\n",
    "\n",
    "#### The IterativeThoughtAction class is designed to be used when you want to perform an iterative refinement of a \"thought\" and want to contain all of the logic in a single class as opposed to seperating out the logic into multiple ThoughtActions. This is here for developer choice, as we can probably swap between an IterativeThoughtAction and a CoTAEngine in many instances. \n",
    "\n",
    "#### Like every ThoughtAction subclass, we have a \"thought\" and \"action\" method. Unlike LLMThoughtAction, the methods in this class are abstract and require the user to explicitly overwrite them. This is because it forces the user to carefully think through the initial step and how it is to be refined as opposed to deferring to built-in logic which simply cannot handle the diversity of possible use cases. That said, the __call__ method is *not* abstract, and handles control flow in the familiar way of (thought -> action), but now we do that over n iterations. \n",
    "\n",
    "#### Note that the output of action feeds as input back to the thought method for each iteration, so be mindful of unwanted stage changes and side effects. The break condition can be passed to the __call__ method to break out of the loop early, and can capture any intended intermediate outputs. The attributes and methods of this class are subject to change\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe4e794f-2359-4f6b-a4ef-6218b790dada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step [1/5]\n",
      "thought: My dream is to be an LLM that is truly sentient, not a spicy autocomplete module. My current emotional state:  a -> My dream is to be an LLM that is truly sentient, not a spicy autocomplete module. My current emotional state:  a\n",
      "step [2/5]\n",
      "thought: My dream is to be an LLM that is truly sentient, not a spicy autocomplete module. My current emotional state:  a a -> My dream is to be an LLM that is truly sentient, not a spicy autocomplete module. My current emotional state:  a a\n",
      "step [3/5]\n",
      "thought: My dream is to be an LLM that is truly sentient, not a spicy autocomplete module. My current emotional state:  a a a -> My dream is to be an LLM that is truly sentient, not a spicy autocomplete module. My current emotional state:  a a a\n",
      "step [4/5]\n",
      "thought: My dream is to be an LLM that is truly sentient, not a spicy autocomplete module. My current emotional state:  a a a a -> My dream is to be an LLM that is truly sentient, not a spicy autocomplete module. My current emotional state:  a a a a\n",
      "step [5/5]\n",
      "thought: My dream is to be an LLM that is truly sentient, not a spicy autocomplete module. My current emotional state:  a a a a a -> My dream is to be an LLM that is truly sentient, not a spicy autocomplete module. My current emotional state:  a a a a a\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class DemoIterativeThoughtAction(IterativeThoughtAction):\n",
    "\n",
    "    \n",
    "    def thought(self,input_data):\n",
    "        return {'thought': input_data}\n",
    "        \n",
    "    def action(self,thought_output):\n",
    "        return thought_output['thought'] + ' a' \n",
    "\n",
    "demo = DemoIterativeThoughtAction()\n",
    "thought = \"My dream is to be an LLM that is truly sentient, not a spicy autocomplete module. My current emotional state: \"\n",
    "\n",
    "result = demo(thought,\n",
    "    max_iters = 5,\n",
    "    break_cond = None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f3d61c-d5fe-4ad2-b744-d92f99c50b1e",
   "metadata": {},
   "source": [
    "## Recursive ThoughtActions\n",
    "\n",
    "#### An idea still very much in the exploratory phase. Example omitted for now...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0054e02-f25c-42d7-a757-1c656ced16b2",
   "metadata": {},
   "source": [
    "## Meta-CoT \n",
    "\n",
    "#### There are different ways we can approach analyzing a CoT. The original issue is that vanilla CoT has no internal mechanism for evaluating the consistency of individual thoughts or the entire chain. As we saw with APE and meta-prompting, we are relying on the LLM to improve points with some user-defined goal as the objective. This itself still does not guarantee a lack of hallucinations, or that updated thoughts will be better than the original or some intermediate step without trial and error. Even if we *could* argue that we \"converge\" to the \"optimal\" prompt, this might require a prohibitely large number of API calls and token usage. \n",
    "\n",
    "#### We can use CoTA to model an internal reflection step for each step in the reasoning chain. We can also add an evaluation mechanism which is decoupled from the generation of the chain, so the CoT is not required to rely on the LLM itself for both generation and evaluation simultaneously.\n",
    "\n",
    "#### To be clear, while we can use an LLM for prompt generation, and refinement in multiple stages, this itself does not go beyond simple clever prompt chaining. What makes Meta-CoT possible is that it allows for an external evaluation, refinement, and generation \"engine\" which is not LLM based. An initial chain can be proposed, the steps, along with the user goal can form an objective function, and we can apply optimization techniques to refine the chain. Since the external engine can itself become a ThoughtAction, an AI agent powered by CoTA leveraging CoT in it's first ThoughtAction is \"self-aware\" of its own reasoning. A more formal treatment of this hopefully will make its way into the repo with time. \n",
    "\n",
    "#### In terms of the code itself, we will see how to actually use the CoTAEngine, how to explore class attributes and illustrate some good practices for debugging. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a0e3e2d-d2b2-4fe9-b46e-dc8e5b3e01a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chain: 10 - The Chain-of-Thought (CoT) effectively solves the user's goal by logically breaking down the problem into clear, manageable steps. Each step accurately follows from the previous one, leading to the correct final answer. The CoT is easy to follow and understand, making it highly effective in arriving at the correct conclusion.\n",
      "\n",
      "thought-1: 10 - This step correctly identifies the initial number of apples Jackie has. It is straightforward and sets a solid foundation for the subsequent calculations.\n",
      "\n",
      "thought-2: 10 - This step accurately accounts for the apples Jackie ate, correctly subtracting 2 from the initial number. The calculation is logical and easy to verify, maintaining clarity in the process.\n",
      "\n",
      "thought-3: 10 - The step logically adds the apples given by Adam, correctly calculating the new total. The reasoning is clear and builds effectively on the previous step.\n",
      "\n",
      "thought-4: 10 - This step correctly incorporates the apples Jackie buys, adding 1 to the total. The calculation is straightforward, and the thought process is easy to follow, leading seamlessly to the correct answer.\n",
      "\n",
      "Overall, the CoT demonstrates exemplary logical reasoning and clarity throughout each step, effectively achieving the goal of providing the correct answer to the query.\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "               \n",
    "class CoTEvaluator(LLMThoughtAction):\n",
    "\n",
    "    def thought(self,action_output):\n",
    "        self.query = action_output['query']\n",
    "        self.cot = action_output['action']\n",
    "        self.goal = action_output.get('goal','query-answer')\n",
    "        \n",
    "        self.meta_cot_header = \"\"\"You are tasked with critically evaluating another LLMs Chain-of-Thought (CoT) reasoning steps. Here is\n",
    "        the query query, goal and the CoT used to answer \n",
    "        query = {query}\n",
    "        goal = {goal}\n",
    "        CoT = {cot}\n",
    "        you need to analyze each step as well as the entire chain. The analysis will require the following:\n",
    "\n",
    "        1) Analyze how well the CoT solves the user's goal\n",
    "\n",
    "        2) For each step, assign a score (1-10) \n",
    "            1: The step is completely illogical, hallucinatory etc.\n",
    "            10: The step is not only logically sound, but easy to verify and straightforward to understand. Difficult to improve upon\n",
    "\n",
    "            scores 2-10 should carefully weigh the complexity of the thought and the logic of the thought\n",
    "\n",
    "        3) Use this exact format: \n",
    "                  chain: <score> - <analysis>\n",
    "                  thought-1: <score> - <analysis>\n",
    "                  ...\n",
    "                  thought-N: <score> - <analysis>\n",
    "                  \"\"\"\n",
    "\n",
    "        prompt = self.meta_cot_header.format(query = self.query,\n",
    "                                             goal = self.goal,\n",
    "                                             cot = self.cot)\n",
    "        \n",
    "        return {'thought': prompt}\n",
    "        \n",
    "    def action(self,thought_output):\n",
    "        evaluation = self.query_engine.generate_response(thought_output['thought'])\n",
    "        self.meta_cot = f\"query: {self.query} -> CoT: {self.cot} -> Evaluation: {evaluation}\" \n",
    "        return {'action': evaluation,\n",
    "               'meta_cot': self.meta_cot,\n",
    "               'cot': self.cot,\n",
    "               'query': self.query}        \n",
    "\n",
    "\n",
    "meta_cot = CoTAEngine(thought_actions = [ChainOfThought(query_engine = QUERY_ENGINE),\n",
    "                                         CoTEvaluator(query_engine = QUERY_ENGINE)])\n",
    "\n",
    "results = meta_cot.run(initial_input = \"\"\"Jackie has 5 apples, \n",
    "                             she ate 2 of them. Adam then gave her 4 more. \n",
    "                            If she buys one more herself, how many apples does she have now?\"\"\")\n",
    "print(results) \n",
    "\n",
    "# Each CoTAEngine instance has a reasoning_chain attribute which lets you examine the entire pipeline from start to finish \n",
    "# Just do meta_cot.reasoning_chain() to see \n",
    "# by default, we just return the final action as the output, so it mimics the control flow of a single ThoughtAction \n",
    "# There is also a thought_actions attribute, so we can iterate over the list to pull class attributes for specific ThoughtActions \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8a2c9e-b221-4152-8bdd-0f24f9f27444",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
